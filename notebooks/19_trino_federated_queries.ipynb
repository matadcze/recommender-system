{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1000001",
   "metadata": {},
   "source": [
    "# 19 - Trino: Federated Queries\n",
    "\n",
    "Trino (dawniej PrestoSQL) - rozproszony silnik SQL do zapytań na danych z wielu źródeł.\n",
    "\n",
    "**Tematy:**\n",
    "- Architektura Trino: Coordinator, Worker, Connector\n",
    "- Połączenie z Trino z Pythona (biblioteka `trino`)\n",
    "- Konektory: PostgreSQL, Hive (HDFS/Parquet), Memory\n",
    "- Podstawowe zapytania: SELECT, WHERE, GROUP BY, JOIN\n",
    "- Federated queries - łączenie danych z wielu źródeł w jednym SQL\n",
    "- Porównanie Trino vs Spark SQL\n",
    "- EXPLAIN ANALYZE i cost-based optimizer\n",
    "- Przeglądanie katalogów: SHOW CATALOGS, SHOW SCHEMAS, SHOW TABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "## 1. Architektura Trino\n",
    "\n",
    "```\n",
    "                    ┌─────────────────────────────┐\n",
    "                    │     Trino Coordinator        │\n",
    "                    │                             │\n",
    "                    │  - Parser / Planner         │\n",
    "                    │  - Cost-Based Optimizer     │\n",
    "                    │  - Scheduler                │\n",
    "                    │  - REST API (:8080)         │\n",
    "                    └──────────┬──────────────────┘\n",
    "                               │\n",
    "              ┌────────────────┼────────────────┐\n",
    "              ▼                ▼                ▼\n",
    "     ┌──────────────┐ ┌──────────────┐ ┌──────────────┐\n",
    "     │ Trino Worker │ │ Trino Worker │ │ Trino Worker │\n",
    "     │              │ │              │ │              │\n",
    "     │  Execution   │ │  Execution   │ │  Execution   │\n",
    "     │  Engine      │ │  Engine      │ │  Engine      │\n",
    "     └──────┬───────┘ └──────┬───────┘ └──────┬───────┘\n",
    "            │                │                │\n",
    "     ┌──────┴───────┐ ┌─────┴────────┐ ┌─────┴────────┐\n",
    "     │  Connector   │ │  Connector   │ │  Connector   │\n",
    "     │  PostgreSQL  │ │  Hive/HDFS   │ │  Memory      │\n",
    "     └──────────────┘ └──────────────┘ └──────────────┘\n",
    "```\n",
    "\n",
    "### Kluczowe elementy:\n",
    "\n",
    "| Komponent | Rola | Odpowiednik w Spark |\n",
    "|-----------|------|--------------------|\n",
    "| **Coordinator** | Planuje i optymalizuje zapytania, rozdziela pracę | Driver |\n",
    "| **Worker** | Wykonuje fragmenty zapytań (splits) | Executor |\n",
    "| **Connector** | Adapter do źródła danych (wtyczka) | DataSource API |\n",
    "| **Catalog** | Nazwany zestaw schematów (np. `postgresql`, `hive`) | Database |\n",
    "| **Schema** | Zestaw tabel w katalogu | Schema |\n",
    "\n",
    "### Czym Trino różni się od bazy danych?\n",
    "- Trino **nie przechowuje danych** - tylko je odpytuje\n",
    "- Dane zostają w swoim źródle (PostgreSQL, HDFS, S3, Kafka...)\n",
    "- Trino = **compute engine** (jak Spark SQL, ale z naciskiem na interaktywne zapytania)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2000001",
   "metadata": {},
   "source": [
    "## 2. Setup - połączenie z Trino z Pythona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trino pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trino.dbapi import connect\n",
    "import pandas as pd\n",
    "\n",
    "# Connection to Trino coordinator\n",
    "# Trino uses catalogs to organize data sources\n",
    "# Default catalog/schema can be set here, but we can also use fully qualified names\n",
    "conn = connect(\n",
    "    host=\"trino\",\n",
    "    port=8080,\n",
    "    user=\"analyst\",\n",
    "    catalog=\"postgresql\",\n",
    "    schema=\"movielens\"\n",
    ")\n",
    "\n",
    "def run_query(sql, conn=conn):\n",
    "    \"\"\"Execute a Trino query and return results as a pandas DataFrame.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    rows = cursor.fetchall()\n",
    "    return pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "def run_query_print(sql, conn=conn, max_rows=20):\n",
    "    \"\"\"Execute a Trino query, print results and return DataFrame.\"\"\"\n",
    "    df = run_query(sql, conn)\n",
    "    print(f\"Rows: {len(df)}\")\n",
    "    display(df.head(max_rows))\n",
    "    return df\n",
    "\n",
    "# Test connection\n",
    "print(\"Connected to Trino!\")\n",
    "run_query_print(\"SELECT 'Hello from Trino!' AS message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000001",
   "metadata": {},
   "source": [
    "## 3. Konektory Trino\n",
    "\n",
    "Trino używa **konektorów** (connectors) do łączenia się ze źródłami danych. Każdy konektor jest zarejestrowany jako **katalog** (catalog).\n",
    "\n",
    "### Nasze katalogi:\n",
    "\n",
    "| Catalog | Connector | Źródło danych | Opis |\n",
    "|---------|-----------|--------------|------|\n",
    "| `postgresql` | PostgreSQL Connector | PostgreSQL 16 | Ratings, movies - dane transakcyjne |\n",
    "| `hive` | Hive Connector | HDFS (Parquet) | Dane analityczne, duże wolumeny |\n",
    "| `memory` | Memory Connector | RAM Trino | Tymczasowe tabele, cache |\n",
    "| `system` | System Connector | Trino metadata | Informacje o runtime, queries |\n",
    "\n",
    "### Konfiguracja konektorów (pliki `.properties` w Trino):\n",
    "\n",
    "```properties\n",
    "# postgresql.properties\n",
    "connector.name=postgresql\n",
    "connection-url=jdbc:postgresql://postgres:5432/recommender\n",
    "connection-user=recommender\n",
    "connection-password=recommender\n",
    "\n",
    "# hive.properties\n",
    "connector.name=hive\n",
    "hive.metastore.uri=thrift://hive-metastore:9083\n",
    "hive.allow-drop-table=true\n",
    "\n",
    "# memory.properties\n",
    "connector.name=memory\n",
    "memory.max-data-per-node=512MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4000001",
   "metadata": {},
   "source": [
    "## 4. Przeglądanie katalogów i schematów\n",
    "\n",
    "Trino ma wbudowane polecenia do eksploracji metadanych - analogicznie do `INFORMATION_SCHEMA` w PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW CATALOGS - lista wszystkich zarejestrowanych źródeł danych\n",
    "run_query_print(\"SHOW CATALOGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW SCHEMAS - lista schematów w danym katalogu\n",
    "run_query_print(\"SHOW SCHEMAS FROM postgresql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW TABLES - lista tabel w danym schemacie\n",
    "run_query_print(\"SHOW TABLES FROM postgresql.movielens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCRIBE - struktura tabeli (kolumny, typy)\n",
    "run_query_print(\"DESCRIBE postgresql.movielens.ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW COLUMNS - alternatywna składnia\n",
    "run_query_print(\"SHOW COLUMNS FROM postgresql.movielens.movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przeglądanie hive catalog\n",
    "run_query_print(\"SHOW SCHEMAS FROM hive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabele w hive\n",
    "run_query_print(\"SHOW TABLES FROM hive.movielens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory catalog - tymczasowe tabele\n",
    "run_query_print(\"SHOW SCHEMAS FROM memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000001",
   "metadata": {},
   "source": [
    "## 5. Podstawowe zapytania przez Trino\n",
    "\n",
    "Składnia SQL w Trino jest zgodna z ANSI SQL. Główna różnica to **fully qualified names**: `catalog.schema.table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT z WHERE - dane z PostgreSQL przez Trino\n",
    "# Ponieważ conn ma ustawiony catalog=postgresql, schema=movielens,\n",
    "# mozemy uzywac krotkich nazw\n",
    "run_query_print(\"\"\"\n",
    "    SELECT user_id, movie_id, rating\n",
    "    FROM ratings\n",
    "    WHERE rating >= 4.5 AND user_id <= 100\n",
    "    ORDER BY rating DESC\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP BY z HAVING\n",
    "run_query_print(\"\"\"\n",
    "    SELECT user_id,\n",
    "           COUNT(*) AS rating_count,\n",
    "           ROUND(AVG(rating), 2) AS avg_rating,\n",
    "           MIN(rating) AS min_rating,\n",
    "           MAX(rating) AS max_rating\n",
    "    FROM ratings\n",
    "    GROUP BY user_id\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY rating_count DESC\n",
    "    LIMIT 20\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN w Trino - obie tabele z PostgreSQL\n",
    "run_query_print(\"\"\"\n",
    "    SELECT m.title,\n",
    "           COUNT(*) AS num_ratings,\n",
    "           ROUND(AVG(r.rating), 2) AS avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movie_id = m.movie_id\n",
    "    GROUP BY m.title\n",
    "    HAVING COUNT(*) > 5000\n",
    "    ORDER BY avg_rating DESC\n",
    "    LIMIT 20\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully qualified names - jawne wskazanie catalog.schema.table\n",
    "# Przydatne gdy łączymy dane z wielu źródeł\n",
    "run_query_print(\"\"\"\n",
    "    SELECT m.title, COUNT(*) AS cnt\n",
    "    FROM postgresql.movielens.ratings r\n",
    "    JOIN postgresql.movielens.movies m ON r.movie_id = m.movie_id\n",
    "    WHERE r.rating = 5.0\n",
    "    GROUP BY m.title\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTE (Common Table Expressions) - dziala identycznie jak w PostgreSQL i Spark SQL\n",
    "run_query_print(\"\"\"\n",
    "    WITH user_stats AS (\n",
    "        SELECT user_id,\n",
    "               COUNT(*) AS num_ratings,\n",
    "               ROUND(AVG(rating), 2) AS avg_rating\n",
    "        FROM ratings\n",
    "        GROUP BY user_id\n",
    "    ),\n",
    "    user_categories AS (\n",
    "        SELECT *,\n",
    "               CASE\n",
    "                   WHEN num_ratings >= 1000 THEN 'power_user'\n",
    "                   WHEN num_ratings >= 100 THEN 'active'\n",
    "                   WHEN num_ratings >= 20 THEN 'casual'\n",
    "                   ELSE 'rare'\n",
    "               END AS user_category\n",
    "        FROM user_stats\n",
    "    )\n",
    "    SELECT user_category,\n",
    "           COUNT(*) AS num_users,\n",
    "           ROUND(AVG(avg_rating), 2) AS mean_avg_rating,\n",
    "           CAST(ROUND(AVG(num_ratings), 0) AS INTEGER) AS mean_num_ratings\n",
    "    FROM user_categories\n",
    "    GROUP BY user_category\n",
    "    ORDER BY mean_num_ratings DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6000001",
   "metadata": {},
   "source": [
    "## 6. Dane na HDFS (Hive Connector)\n",
    "\n",
    "Hive Connector pozwala Trino odpytywać pliki na HDFS (Parquet, ORC, CSV, JSON) zarejestrowane w Hive Metastore.\n",
    "\n",
    "### Jak dane trafiają do Hive?\n",
    "1. Spark zapisuje Parquet na HDFS (notebook 15, 16)\n",
    "2. Tabela jest zarejestrowana w Hive Metastore (CREATE TABLE / saveAsTable)\n",
    "3. Trino widzi tabelę przez Hive Connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdz co jest dostepne w hive catalog\n",
    "run_query_print(\"SHOW SCHEMAS FROM hive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyklady tabel hive (Parquet na HDFS)\n",
    "run_query_print(\"SHOW TABLES FROM hive.movielens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odczyt danych z HDFS przez Trino\n",
    "run_query_print(\"\"\"\n",
    "    SELECT *\n",
    "    FROM hive.movielens.ratings\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analityka na danych HDFS - identyczny SQL!\n",
    "run_query_print(\"\"\"\n",
    "    SELECT movie_id,\n",
    "           COUNT(*) AS num_ratings,\n",
    "           ROUND(AVG(rating), 2) AS avg_rating\n",
    "    FROM hive.movielens.ratings\n",
    "    GROUP BY movie_id\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY avg_rating DESC\n",
    "    LIMIT 15\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory connector - tymczasowe tabele w RAM Trino\n",
    "# Przydatne do cache'owania wynikow posrednich\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Utworz schema w memory\n",
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS memory.temp\")\n",
    "\n",
    "# Utworz tabele w pamieci z wynikiem zapytania\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS memory.temp.movie_stats AS\n",
    "    SELECT movie_id,\n",
    "           COUNT(*) AS num_ratings,\n",
    "           AVG(rating) AS avg_rating,\n",
    "           STDDEV(rating) AS std_rating\n",
    "    FROM postgresql.movielens.ratings\n",
    "    GROUP BY movie_id\n",
    "\"\"\")\n",
    "\n",
    "# Teraz tabela jest w pamięci - ultra szybki dostęp\n",
    "run_query_print(\"\"\"\n",
    "    SELECT * FROM memory.temp.movie_stats\n",
    "    ORDER BY num_ratings DESC\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7000001",
   "metadata": {},
   "source": [
    "## 7. Federated Queries - serce Trino!\n",
    "\n",
    "Najważniejsza cecha Trino: **jeden SQL łączy dane z wielu źródeł** - bez kopiowania danych!\n",
    "\n",
    "```\n",
    "┌──────────────────────────────────────────────────────┐\n",
    "│                   Trino SQL Query                     │\n",
    "│                                                       │\n",
    "│  SELECT pg.title, hdfs.avg_rating, mem.user_segment  │\n",
    "│  FROM postgresql.movielens.movies pg                  │\n",
    "│  JOIN hive.movielens.ratings_agg hdfs                 │\n",
    "│  JOIN memory.temp.user_segments mem                   │\n",
    "│                                                       │\n",
    "│     ┌──────────┐  ┌──────────┐  ┌──────────┐        │\n",
    "│     │PostgreSQL │  │   HDFS   │  │  Memory  │        │\n",
    "│     │  movies   │  │ ratings  │  │ segments │        │\n",
    "│     └──────────┘  └──────────┘  └──────────┘        │\n",
    "└──────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "Trino:\n",
    "1. Parsuje zapytanie\n",
    "2. Rozpoznaje, które tabele są w których katalogach\n",
    "3. Wysyła odpowiednie zapytania do każdego źródła (pushdown!)\n",
    "4. Łączy wyniki w pamięci Workerów\n",
    "5. Zwraca jeden wynik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEDERATED QUERY: PostgreSQL + HDFS\n",
    "# Metadata filmow z PostgreSQL + statystyki ocen z HDFS (Parquet)\n",
    "run_query_print(\"\"\"\n",
    "    SELECT m.title,\n",
    "           m.genres,\n",
    "           h.num_ratings,\n",
    "           ROUND(h.avg_rating, 2) AS avg_rating\n",
    "    FROM postgresql.movielens.movies m\n",
    "    JOIN (\n",
    "        SELECT movie_id,\n",
    "               COUNT(*) AS num_ratings,\n",
    "               AVG(rating) AS avg_rating\n",
    "        FROM hive.movielens.ratings\n",
    "        GROUP BY movie_id\n",
    "    ) h ON m.movie_id = h.movie_id\n",
    "    WHERE h.num_ratings > 5000\n",
    "    ORDER BY h.avg_rating DESC\n",
    "    LIMIT 20\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEDERATED QUERY: PostgreSQL + HDFS + Memory\n",
    "# 3 źródła danych w jednym zapytaniu!\n",
    "run_query_print(\"\"\"\n",
    "    WITH hdfs_user_stats AS (\n",
    "        SELECT user_id,\n",
    "               COUNT(*) AS num_ratings,\n",
    "               AVG(rating) AS avg_rating\n",
    "        FROM hive.movielens.ratings\n",
    "        GROUP BY user_id\n",
    "    ),\n",
    "    top_users AS (\n",
    "        SELECT user_id, num_ratings, avg_rating\n",
    "        FROM hdfs_user_stats\n",
    "        WHERE num_ratings > 500\n",
    "    )\n",
    "    SELECT tu.user_id,\n",
    "           tu.num_ratings AS user_total_ratings,\n",
    "           ROUND(tu.avg_rating, 2) AS user_avg_rating,\n",
    "           m.title,\n",
    "           r.rating AS user_movie_rating,\n",
    "           ROUND(ms.avg_rating, 2) AS movie_global_avg\n",
    "    FROM top_users tu\n",
    "    JOIN postgresql.movielens.ratings r ON tu.user_id = r.user_id\n",
    "    JOIN postgresql.movielens.movies m ON r.movie_id = m.movie_id\n",
    "    JOIN memory.temp.movie_stats ms ON r.movie_id = ms.movie_id\n",
    "    WHERE r.rating = 5.0\n",
    "      AND ms.num_ratings > 10000\n",
    "    ORDER BY tu.num_ratings DESC, m.title\n",
    "    LIMIT 20\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porównanie tych samych danych z różnych źródeł\n",
    "# Weryfikacja spójności: PostgreSQL vs HDFS\n",
    "run_query_print(\"\"\"\n",
    "    SELECT 'PostgreSQL' AS source,\n",
    "           COUNT(*) AS total_ratings,\n",
    "           COUNT(DISTINCT user_id) AS unique_users,\n",
    "           COUNT(DISTINCT movie_id) AS unique_movies,\n",
    "           ROUND(AVG(rating), 4) AS avg_rating\n",
    "    FROM postgresql.movielens.ratings\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT 'HDFS (Hive)' AS source,\n",
    "           COUNT(*) AS total_ratings,\n",
    "           COUNT(DISTINCT user_id) AS unique_users,\n",
    "           COUNT(DISTINCT movie_id) AS unique_movies,\n",
    "           ROUND(AVG(rating), 4) AS avg_rating\n",
    "    FROM hive.movielens.ratings\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8000001",
   "metadata": {},
   "source": [
    "## 8. Trino vs Spark SQL - kiedy co użyć?\n",
    "\n",
    "| Cecha | Trino | Spark SQL |\n",
    "|-------|-------|-----------|\n",
    "| **Główne zastosowanie** | Interaktywne zapytania, ad-hoc analytics | Batch processing, ETL, ML |\n",
    "| **Latencja** | Niska (sekundy) | Wyższa (minuty) - narzut startu |\n",
    "| **Przetwarzanie** | Pipeline (streaming między stages) | Stage-based (shuffle na dysk) |\n",
    "| **Fault tolerance** | Brak - query restart przy awarii | Tak - retry na poziomie task |\n",
    "| **Dane pośrednie** | W pamięci (szybko, ale limitowane) | Na dysku (wolniej, ale skalowalne) |\n",
    "| **Federated queries** | Natywne - wiele katalogów | Możliwe, ale bardziej złożone |\n",
    "| **UDF** | Ograniczone (Java/Trino plugins) | Bogata obsługa (Python, Scala) |\n",
    "| **ML** | Brak wbudowanego | MLlib, ML Pipelines |\n",
    "| **Ekosystem** | SQL-first | Programistyczny (Python/Scala + SQL) |\n",
    "\n",
    "### Kiedy Trino?\n",
    "- Szybkie, interaktywne zapytania analityczne (dashboardy, raporty)\n",
    "- Odpytywanie wielu źródeł danych jednocześnie (federated queries)\n",
    "- Ad-hoc analiza - analityk zadaje pytania bez pisania kodu\n",
    "- Narzut startu Spark jest zbyt duży dla prostych zapytań\n",
    "- BI tools (Tableau, Superset, Metabase) potrzebują szybkiego SQL endpoint\n",
    "\n",
    "### Kiedy Spark SQL?\n",
    "- Duże transformacje ETL (terabajty danych)\n",
    "- Machine learning (MLlib, integration z Python ML ecosystem)\n",
    "- Złożone pipeline'y wymagające fault tolerance\n",
    "- Streaming (Structured Streaming)\n",
    "- Gdy potrzebna jest programistyczna kontrola (DataFrames, UDFs w Pythonie)\n",
    "\n",
    "### W praktyce: razem!\n",
    "```\n",
    "Spark (batch ETL) → HDFS/S3 (Parquet) → Trino (interaktywne zapytania)\n",
    "```\n",
    "Spark przetwarza i zapisuje dane, Trino odpytuje je interaktywnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: Trino query latency\n",
    "import time\n",
    "\n",
    "queries = {\n",
    "    \"simple_count\": \"SELECT COUNT(*) FROM postgresql.movielens.ratings\",\n",
    "    \"group_by\": \"\"\"\n",
    "        SELECT movie_id, COUNT(*) AS cnt, AVG(rating) AS avg_r\n",
    "        FROM postgresql.movielens.ratings\n",
    "        GROUP BY movie_id\n",
    "        ORDER BY cnt DESC\n",
    "        LIMIT 10\n",
    "    \"\"\",\n",
    "    \"join_query\": \"\"\"\n",
    "        SELECT m.title, COUNT(*) AS cnt\n",
    "        FROM postgresql.movielens.ratings r\n",
    "        JOIN postgresql.movielens.movies m ON r.movie_id = m.movie_id\n",
    "        WHERE r.rating >= 4.0\n",
    "        GROUP BY m.title\n",
    "        ORDER BY cnt DESC\n",
    "        LIMIT 10\n",
    "    \"\"\",\n",
    "    \"federated\": \"\"\"\n",
    "        SELECT m.title, h.avg_rating\n",
    "        FROM postgresql.movielens.movies m\n",
    "        JOIN (\n",
    "            SELECT movie_id, AVG(rating) AS avg_rating\n",
    "            FROM hive.movielens.ratings\n",
    "            GROUP BY movie_id\n",
    "            HAVING COUNT(*) > 1000\n",
    "        ) h ON m.movie_id = h.movie_id\n",
    "        ORDER BY h.avg_rating DESC\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "for name, sql in queries.items():\n",
    "    start = time.time()\n",
    "    run_query(sql)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"{name:<20} {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9000001",
   "metadata": {},
   "source": [
    "## 9. EXPLAIN ANALYZE - Cost-Based Optimizer\n",
    "\n",
    "Trino ma zaawansowany **Cost-Based Optimizer (CBO)**, który:\n",
    "- Zbiera statystyki o tabelach (rozmiar, cardinalność, rozkład wartości)\n",
    "- Wybiera optymalną kolejność joinów\n",
    "- Decyduje o strategii join (broadcast vs distributed)\n",
    "- Wykonuje predicate pushdown do źródeł danych\n",
    "\n",
    "### EXPLAIN vs EXPLAIN ANALYZE:\n",
    "- `EXPLAIN` - pokazuje plan zapytania **bez wykonania**\n",
    "- `EXPLAIN ANALYZE` - wykonuje zapytanie i pokazuje **rzeczywiste** koszty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAIN - plan logiczny\n",
    "explain_result = run_query(\"\"\"\n",
    "    EXPLAIN\n",
    "    SELECT m.title, COUNT(*) AS num_ratings, AVG(r.rating) AS avg_rating\n",
    "    FROM postgresql.movielens.ratings r\n",
    "    JOIN postgresql.movielens.movies m ON r.movie_id = m.movie_id\n",
    "    GROUP BY m.title\n",
    "    ORDER BY num_ratings DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "# Plan jest w jednej kolumnie - wypisz czytelnie\n",
    "for _, row in explain_result.iterrows():\n",
    "    print(row.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAIN ANALYZE - rzeczywiste wykonanie z metrykami\n",
    "explain_analyze = run_query(\"\"\"\n",
    "    EXPLAIN ANALYZE\n",
    "    SELECT m.title, COUNT(*) AS num_ratings, AVG(r.rating) AS avg_rating\n",
    "    FROM postgresql.movielens.ratings r\n",
    "    JOIN postgresql.movielens.movies m ON r.movie_id = m.movie_id\n",
    "    GROUP BY m.title\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY avg_rating DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "for _, row in explain_analyze.iterrows():\n",
    "    print(row.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAIN z roznym typem wyjscia\n",
    "# EXPLAIN (TYPE DISTRIBUTED) - plan z uwzglednieniem partycjonowania\n",
    "distributed_plan = run_query(\"\"\"\n",
    "    EXPLAIN (TYPE DISTRIBUTED)\n",
    "    SELECT m.title, COUNT(*) AS num_ratings\n",
    "    FROM postgresql.movielens.ratings r\n",
    "    JOIN postgresql.movielens.movies m ON r.movie_id = m.movie_id\n",
    "    GROUP BY m.title\n",
    "    ORDER BY num_ratings DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "for _, row in distributed_plan.iterrows():\n",
    "    print(row.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAIN na federated query - zobaczmy jak Trino rozkłada pracę miedzy źródła\n",
    "federated_plan = run_query(\"\"\"\n",
    "    EXPLAIN ANALYZE\n",
    "    SELECT m.title,\n",
    "           pg_r.pg_count,\n",
    "           hdfs_r.hdfs_count\n",
    "    FROM postgresql.movielens.movies m\n",
    "    JOIN (\n",
    "        SELECT movie_id, COUNT(*) AS pg_count\n",
    "        FROM postgresql.movielens.ratings\n",
    "        GROUP BY movie_id\n",
    "    ) pg_r ON m.movie_id = pg_r.movie_id\n",
    "    JOIN (\n",
    "        SELECT movie_id, COUNT(*) AS hdfs_count\n",
    "        FROM hive.movielens.ratings\n",
    "        GROUP BY movie_id\n",
    "    ) hdfs_r ON m.movie_id = hdfs_r.movie_id\n",
    "    ORDER BY pg_r.pg_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "for _, row in federated_plan.iterrows():\n",
    "    print(row.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9000002",
   "metadata": {},
   "source": [
    "### Co warto obserwować w EXPLAIN ANALYZE:\n",
    "\n",
    "| Metryka | Opis | Na co zwrócić uwagę |\n",
    "|---------|------|---------------------|\n",
    "| **Rows** | Liczba przetworzonych wierszy | Czy optimizer dobrze estymuje? |\n",
    "| **CPU time** | Czas CPU na danym etapie | Gdzie bottleneck? |\n",
    "| **Wall time** | Rzeczywisty czas | Czy czekamy na I/O? |\n",
    "| **Connector pushdown** | Filtr przesunięty do źródła | Mniej danych transferowanych |\n",
    "| **Join strategy** | HASH vs BROADCAST | Broadcast dla małych tabel |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10000001",
   "metadata": {},
   "source": [
    "## 10. Zaawansowane federated queries\n",
    "\n",
    "Kilka praktycznych wzorców użycia federated queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wzorzec 1: Enrichment - wzbogacenie danych z HDFS metadanymi z PostgreSQL\n",
    "run_query_print(\"\"\"\n",
    "    WITH hdfs_ratings AS (\n",
    "        SELECT movie_id,\n",
    "               user_id,\n",
    "               rating,\n",
    "               rating_timestamp\n",
    "        FROM hive.movielens.ratings\n",
    "        WHERE rating >= 4.5\n",
    "    )\n",
    "    SELECT m.title,\n",
    "           m.genres,\n",
    "           COUNT(*) AS high_ratings,\n",
    "           MIN(hr.rating_timestamp) AS first_high_rating,\n",
    "           MAX(hr.rating_timestamp) AS last_high_rating\n",
    "    FROM hdfs_ratings hr\n",
    "    JOIN postgresql.movielens.movies m ON hr.movie_id = m.movie_id\n",
    "    GROUP BY m.title, m.genres\n",
    "    ORDER BY high_ratings DESC\n",
    "    LIMIT 15\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wzorzec 2: Cross-source aggregation\n",
    "# Porownaj wyniki agregacji z PostgreSQL i HDFS per movie\n",
    "run_query_print(\"\"\"\n",
    "    WITH pg_stats AS (\n",
    "        SELECT movie_id,\n",
    "               COUNT(*) AS pg_count,\n",
    "               ROUND(AVG(rating), 3) AS pg_avg\n",
    "        FROM postgresql.movielens.ratings\n",
    "        GROUP BY movie_id\n",
    "    ),\n",
    "    hdfs_stats AS (\n",
    "        SELECT movie_id,\n",
    "               COUNT(*) AS hdfs_count,\n",
    "               ROUND(AVG(rating), 3) AS hdfs_avg\n",
    "        FROM hive.movielens.ratings\n",
    "        GROUP BY movie_id\n",
    "    )\n",
    "    SELECT m.title,\n",
    "           pg.pg_count,\n",
    "           h.hdfs_count,\n",
    "           pg.pg_avg,\n",
    "           h.hdfs_avg,\n",
    "           ABS(pg.pg_avg - h.hdfs_avg) AS avg_diff\n",
    "    FROM pg_stats pg\n",
    "    JOIN hdfs_stats h ON pg.movie_id = h.movie_id\n",
    "    JOIN postgresql.movielens.movies m ON pg.movie_id = m.movie_id\n",
    "    WHERE pg.pg_count > 1000\n",
    "    ORDER BY avg_diff DESC\n",
    "    LIMIT 15\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wzorzec 3: CREATE TABLE AS SELECT (CTAS) - materializacja wynikow\n",
    "# Zapisz wynik federated query do memory lub hive\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS memory.temp.movie_enriched AS\n",
    "    SELECT m.movie_id,\n",
    "           m.title,\n",
    "           m.genres,\n",
    "           COALESCE(r.num_ratings, 0) AS num_ratings,\n",
    "           COALESCE(r.avg_rating, 0) AS avg_rating,\n",
    "           COALESCE(r.std_rating, 0) AS std_rating\n",
    "    FROM postgresql.movielens.movies m\n",
    "    LEFT JOIN memory.temp.movie_stats r ON m.movie_id = r.movie_id\n",
    "\"\"\")\n",
    "\n",
    "run_query_print(\"\"\"\n",
    "    SELECT * FROM memory.temp.movie_enriched\n",
    "    WHERE num_ratings > 10000\n",
    "    ORDER BY avg_rating DESC\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11000001",
   "metadata": {},
   "source": [
    "## 11. System Connector - monitorowanie Trino\n",
    "\n",
    "Trino ma wbudowany `system` catalog z informacjami o runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informacje o wersji i wezlach\n",
    "run_query_print(\"SELECT * FROM system.runtime.nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aktualnie wykonywane zapytania\n",
    "run_query_print(\"\"\"\n",
    "    SELECT query_id, state, query, started\n",
    "    FROM system.runtime.queries\n",
    "    ORDER BY started DESC\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informacje o taskach\n",
    "run_query_print(\"\"\"\n",
    "    SELECT node_id,\n",
    "           COUNT(*) AS num_tasks,\n",
    "           SUM(input_rows) AS total_input_rows,\n",
    "           SUM(output_rows) AS total_output_rows\n",
    "    FROM system.runtime.tasks\n",
    "    GROUP BY node_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12000001",
   "metadata": {},
   "source": [
    "## Zadanie 1\n",
    "\n",
    "Napisz **federated query**, które łączy dane z **3 źródeł** (PostgreSQL, Hive/HDFS, Memory):\n",
    "\n",
    "1. Z `postgresql.movielens.movies` - weź tytuły i gatunki filmów\n",
    "2. Z `hive.movielens.ratings` - oblicz statystyki ocen per film (count, avg, min, max)\n",
    "3. Z `memory.temp.movie_stats` (utworzony wcześniej) - weź odchylenie standardowe\n",
    "\n",
    "Wynik powinien zawierać:\n",
    "- Tytuł filmu, gatunek\n",
    "- Liczbę ocen, średnią, min, max, odchylenie standardowe\n",
    "- Tylko filmy z > 5000 ocen\n",
    "- Posortowane po odchyleniu standardowym malejąco (najbardziej \"kontrowersyjne\" filmy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n",
    "run_query_print(\"\"\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13000001",
   "metadata": {},
   "source": [
    "## Zadanie końcowe\n",
    "\n",
    "Zbuduj **analytyczny dashboard query** łączący dane z PostgreSQL + HDFS:\n",
    "\n",
    "Stwórz raport, który w jednym zapytaniu (federated!) pokaże:\n",
    "\n",
    "1. **Top 10 filmów** - z PostgreSQL (`movies`) + HDFS (`ratings`):\n",
    "   - Tytuł, gatunek, liczba ocen, średnia ocena\n",
    "   - Filtruj: minimum 10000 ocen\n",
    "\n",
    "2. **Segmentacja użytkowników** - z HDFS (`ratings`):\n",
    "   - Power users (>1000 ocen), Active (100-1000), Casual (20-100), Rare (<20)\n",
    "   - Dla każdego segmentu: liczba użytkowników, średnia ocena, średnia liczba ocen\n",
    "\n",
    "3. **Trend popularności** - z HDFS (`ratings`) + PostgreSQL (`movies`):\n",
    "   - Wyciągnij rok z tytułu filmu (np. \"Toy Story (1995)\" → 1995)\n",
    "   - Ile ocen zebrały filmy per dekada (1990s, 2000s, 2010s)\n",
    "   - Średnia ocena per dekada\n",
    "\n",
    "Zapisz wynik każdej części do `memory.temp` jako osobną tabelę, a na końcu połącz w summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n",
    "\n",
    "# Część 1: Top 10 filmów\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS memory.temp.dashboard_top_movies AS\n",
    "    SELECT 1 AS placeholder\n",
    "    -- Twoje zapytanie tutaj\n",
    "\"\"\")\n",
    "\n",
    "run_query_print(\"SELECT * FROM memory.temp.dashboard_top_movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Część 2: Segmentacja użytkowników\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Część 3: Trend popularności per dekada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podsumowanie: polacz wszystkie czesci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup memory tables\n",
    "cursor = conn.cursor()\n",
    "for table in ['movie_stats', 'movie_enriched', 'dashboard_top_movies']:\n",
    "    try:\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS memory.temp.{table}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not drop {table}: {e}\")\n",
    "\n",
    "conn.close()\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
