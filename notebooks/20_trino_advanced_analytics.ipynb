{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1000001",
   "metadata": {},
   "source": [
    "# 20 - Trino: Advanced Analytics\n",
    "\n",
    "Zaawansowana analityka w Trino - funkcje okienkowe, funkcje przybliżone, optymalizacja.\n",
    "\n",
    "**Tematy:**\n",
    "- Window functions w Trino (porównanie z notebook 05 Spark SQL)\n",
    "- Approximate functions: approx_distinct, approx_percentile\n",
    "- Tablice i mapy w Trino SQL\n",
    "- Trino + dbt - transformacje SQL jako kod\n",
    "- Materialized views\n",
    "- Partycjonowanie i bucketing w Hive connector\n",
    "- Optymalizacja: partition pruning, predicate pushdown\n",
    "- Performance tuning: session properties, resource groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trino.dbapi import connect\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "conn = connect(\n",
    "    host=\"trino\",\n",
    "    port=8080,\n",
    "    user=\"analyst\",\n",
    "    catalog=\"postgresql\",\n",
    "    schema=\"movielens\"\n",
    ")\n",
    "\n",
    "def run_query(sql, conn=conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    rows = cursor.fetchall()\n",
    "    return pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "def run_query_print(sql, conn=conn, max_rows=20):\n",
    "    df = run_query(sql, conn)\n",
    "    print(f\"Rows: {len(df)}\")\n",
    "    display(df.head(max_rows))\n",
    "    return df\n",
    "\n",
    "print(\"Connected to Trino!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2000001",
   "metadata": {},
   "source": [
    "## 2. Window Functions w Trino\n",
    "\n",
    "Window functions w Trino działają identycznie jak w Spark SQL (notebook 05). Składnia ANSI SQL.\n",
    "\n",
    "Dostępne funkcje:\n",
    "- `ROW_NUMBER()`, `RANK()`, `DENSE_RANK()` - numeracja/ranking\n",
    "- `LAG()`, `LEAD()` - poprzedni/następny wiersz\n",
    "- `FIRST_VALUE()`, `LAST_VALUE()`, `NTH_VALUE()` - wartości z okna\n",
    "- `SUM() OVER`, `AVG() OVER`, `COUNT() OVER` - agregaty okienkowe\n",
    "- `NTILE(n)` - podział na grupy\n",
    "- `CUME_DIST()`, `PERCENT_RANK()` - dystrybucja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROW_NUMBER - top 3 filmy per użytkownik (identycznie jak w Spark SQL)\n",
    "run_query_print(\"\"\"\n",
    "    SELECT user_id, movie_id, rating, rn\n",
    "    FROM (\n",
    "        SELECT user_id, movie_id, rating,\n",
    "               ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY rating DESC) AS rn\n",
    "        FROM ratings\n",
    "    )\n",
    "    WHERE rn <= 3 AND user_id <= 5\n",
    "    ORDER BY user_id, rn\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANK vs DENSE_RANK\n",
    "run_query_print(\"\"\"\n",
    "    SELECT user_id, movie_id, rating,\n",
    "           RANK() OVER (PARTITION BY user_id ORDER BY rating DESC) AS rank_val,\n",
    "           DENSE_RANK() OVER (PARTITION BY user_id ORDER BY rating DESC) AS dense_rank_val\n",
    "    FROM ratings\n",
    "    WHERE user_id = 1\n",
    "    LIMIT 15\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAG / LEAD - zmiana oceny użytkownika w czasie\n",
    "run_query_print(\"\"\"\n",
    "    SELECT user_id, movie_id, rating, rating_timestamp,\n",
    "           LAG(rating) OVER (PARTITION BY user_id ORDER BY rating_timestamp) AS prev_rating,\n",
    "           rating - LAG(rating) OVER (PARTITION BY user_id ORDER BY rating_timestamp) AS rating_diff\n",
    "    FROM ratings\n",
    "    WHERE user_id = 42\n",
    "    ORDER BY rating_timestamp\n",
    "    LIMIT 20\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kumulatywna suma i średnia krocząca\n",
    "run_query_print(\"\"\"\n",
    "    SELECT user_id, movie_id, rating, rating_timestamp,\n",
    "           COUNT(*) OVER (\n",
    "               PARTITION BY user_id ORDER BY rating_timestamp\n",
    "           ) AS cumulative_count,\n",
    "           ROUND(AVG(rating) OVER (\n",
    "               PARTITION BY user_id\n",
    "               ORDER BY rating_timestamp\n",
    "               ROWS BETWEEN 4 PRECEDING AND CURRENT ROW\n",
    "           ), 2) AS moving_avg_5\n",
    "    FROM ratings\n",
    "    WHERE user_id = 42\n",
    "    ORDER BY rating_timestamp\n",
    "    LIMIT 20\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NTILE - podział na kwartyle\n",
    "run_query_print(\"\"\"\n",
    "    WITH user_avg AS (\n",
    "        SELECT user_id, AVG(rating) AS avg_rating, COUNT(*) AS cnt\n",
    "        FROM ratings\n",
    "        GROUP BY user_id\n",
    "        HAVING COUNT(*) >= 50\n",
    "    )\n",
    "    SELECT quartile,\n",
    "           COUNT(*) AS num_users,\n",
    "           ROUND(MIN(avg_rating), 2) AS min_avg,\n",
    "           ROUND(MAX(avg_rating), 2) AS max_avg\n",
    "    FROM (\n",
    "        SELECT *, NTILE(4) OVER (ORDER BY avg_rating) AS quartile\n",
    "        FROM user_avg\n",
    "    )\n",
    "    GROUP BY quartile\n",
    "    ORDER BY quartile\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUME_DIST i PERCENT_RANK - funkcje dystrybucji (niedostępne łatwo w Spark SQL)\n",
    "run_query_print(\"\"\"\n",
    "    WITH movie_stats AS (\n",
    "        SELECT movie_id,\n",
    "               COUNT(*) AS num_ratings,\n",
    "               AVG(rating) AS avg_rating\n",
    "        FROM ratings\n",
    "        GROUP BY movie_id\n",
    "        HAVING COUNT(*) >= 100\n",
    "    )\n",
    "    SELECT m.title,\n",
    "           ms.num_ratings,\n",
    "           ROUND(ms.avg_rating, 2) AS avg_rating,\n",
    "           ROUND(CUME_DIST() OVER (ORDER BY ms.avg_rating), 3) AS cume_dist,\n",
    "           ROUND(PERCENT_RANK() OVER (ORDER BY ms.avg_rating), 3) AS pct_rank\n",
    "    FROM movie_stats ms\n",
    "    JOIN movies m ON ms.movie_id = m.movie_id\n",
    "    ORDER BY ms.avg_rating DESC\n",
    "    LIMIT 15\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST_VALUE / LAST_VALUE - unikalne dla Trino (łatwiejsze niż w Spark)\n",
    "run_query_print(\"\"\"\n",
    "    SELECT user_id,\n",
    "           movie_id,\n",
    "           rating,\n",
    "           rating_timestamp,\n",
    "           FIRST_VALUE(rating) OVER (\n",
    "               PARTITION BY user_id ORDER BY rating_timestamp\n",
    "           ) AS first_rating,\n",
    "           LAST_VALUE(rating) OVER (\n",
    "               PARTITION BY user_id\n",
    "               ORDER BY rating_timestamp\n",
    "               ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "           ) AS last_rating\n",
    "    FROM ratings\n",
    "    WHERE user_id <= 3\n",
    "    ORDER BY user_id, rating_timestamp\n",
    "    LIMIT 20\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000001",
   "metadata": {},
   "source": [
    "## 3. Approximate Functions\n",
    "\n",
    "Trino oferuje **funkcje przybliżone**, które działają znacznie szybciej na dużych zbiorach danych kosztem niewielkiej niedokładności.\n",
    "\n",
    "| Funkcja | Dokładny odpowiednik | Algorytm | Błąd |\n",
    "|---------|---------------------|----------|------|\n",
    "| `approx_distinct()` | `COUNT(DISTINCT)` | HyperLogLog | ~2.3% |\n",
    "| `approx_percentile(col, p)` | percentyl z sortowania | T-Digest / QDigest | konfigurowalny |\n",
    "| `approx_most_frequent(n, col, cap)` | GROUP BY + ORDER BY + LIMIT | Count-Min Sketch | przybliżony |\n",
    "\n",
    "Przydatne gdy:\n",
    "- Dane są bardzo duże (miliardy wierszy)\n",
    "- Potrzebna szybka odpowiedź (dashboard)\n",
    "- Dokładność 98% wystarczy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approx_distinct vs COUNT(DISTINCT) - porównanie dokładności i szybkości\n",
    "run_query_print(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(DISTINCT user_id) AS exact_users,\n",
    "        approx_distinct(user_id) AS approx_users,\n",
    "        COUNT(DISTINCT movie_id) AS exact_movies,\n",
    "        approx_distinct(movie_id) AS approx_movies\n",
    "    FROM ratings\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: approx_distinct vs COUNT(DISTINCT)\n",
    "for name, sql in [\n",
    "    (\"COUNT(DISTINCT)\", \"SELECT COUNT(DISTINCT user_id) FROM ratings\"),\n",
    "    (\"approx_distinct\", \"SELECT approx_distinct(user_id) FROM ratings\"),\n",
    "]:\n",
    "    start = time.time()\n",
    "    run_query(sql)\n",
    "    print(f\"{name:<20} {time.time() - start:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approx_percentile - szybkie percentyle\n",
    "run_query_print(\"\"\"\n",
    "    SELECT\n",
    "        approx_percentile(rating, 0.25) AS p25,\n",
    "        approx_percentile(rating, 0.50) AS median,\n",
    "        approx_percentile(rating, 0.75) AS p75,\n",
    "        approx_percentile(rating, 0.90) AS p90,\n",
    "        approx_percentile(rating, 0.99) AS p99\n",
    "    FROM ratings\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approx_percentile z wieloma wartościami naraz (tablica percentyli)\n",
    "run_query_print(\"\"\"\n",
    "    SELECT movie_id,\n",
    "           COUNT(*) AS cnt,\n",
    "           ROUND(AVG(rating), 2) AS avg_rating,\n",
    "           approx_percentile(rating, 0.5) AS median_rating,\n",
    "           approx_percentile(rating, ARRAY[0.25, 0.5, 0.75]) AS quartiles\n",
    "    FROM ratings\n",
    "    GROUP BY movie_id\n",
    "    HAVING COUNT(*) > 10000\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approx_distinct per grupa - unikalni użytkownicy per ocena\n",
    "run_query_print(\"\"\"\n",
    "    SELECT\n",
    "        CAST(rating AS VARCHAR) AS rating_val,\n",
    "        COUNT(*) AS total,\n",
    "        approx_distinct(user_id) AS approx_unique_users,\n",
    "        approx_distinct(movie_id) AS approx_unique_movies\n",
    "    FROM ratings\n",
    "    GROUP BY rating\n",
    "    ORDER BY rating DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4000001",
   "metadata": {},
   "source": [
    "## 4. Tablice i mapy w Trino SQL\n",
    "\n",
    "Trino ma natywne wsparcie dla złożonych typów danych:\n",
    "- `ARRAY` - lista wartości\n",
    "- `MAP` - słownik klucz-wartość\n",
    "- `ROW` - struktura (named tuple)\n",
    "\n",
    "Przydatne do pracy z danymi semi-strukturalnymi (JSON, genres itp.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT - rozdzielenie genres na tablicę\n",
    "run_query_print(\"\"\"\n",
    "    SELECT title,\n",
    "           genres,\n",
    "           SPLIT(genres, '|') AS genre_array,\n",
    "           CARDINALITY(SPLIT(genres, '|')) AS num_genres\n",
    "    FROM movies\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNNEST - rozwinięcie tablicy do wierszy (odpowiednik explode w Spark)\n",
    "run_query_print(\"\"\"\n",
    "    SELECT m.movie_id, m.title, genre\n",
    "    FROM movies m\n",
    "    CROSS JOIN UNNEST(SPLIT(m.genres, '|')) AS t(genre)\n",
    "    WHERE m.movie_id <= 5\n",
    "    ORDER BY m.movie_id, genre\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analiza gatunków z UNNEST\n",
    "run_query_print(\"\"\"\n",
    "    WITH genre_exploded AS (\n",
    "        SELECT m.movie_id, m.title, genre\n",
    "        FROM movies m\n",
    "        CROSS JOIN UNNEST(SPLIT(m.genres, '|')) AS t(genre)\n",
    "    )\n",
    "    SELECT genre,\n",
    "           COUNT(DISTINCT movie_id) AS num_movies\n",
    "    FROM genre_exploded\n",
    "    WHERE genre != '(no genres listed)'\n",
    "    GROUP BY genre\n",
    "    ORDER BY num_movies DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARRAY aggregation - zbierz oceny użytkownika do tablicy\n",
    "run_query_print(\"\"\"\n",
    "    SELECT user_id,\n",
    "           COUNT(*) AS num_ratings,\n",
    "           ARRAY_AGG(rating ORDER BY rating_timestamp) AS rating_history,\n",
    "           ARRAY_AGG(DISTINCT CAST(rating AS VARCHAR)) AS unique_ratings\n",
    "    FROM ratings\n",
    "    WHERE user_id <= 3\n",
    "    GROUP BY user_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP - tworzenie map z danych\n",
    "run_query_print(\"\"\"\n",
    "    SELECT user_id,\n",
    "           MAP_AGG(movie_id, rating) AS movie_ratings_map\n",
    "    FROM ratings\n",
    "    WHERE user_id = 1\n",
    "    GROUP BY user_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operacje na tablicach: CONTAINS, ELEMENT_AT, ARRAY_JOIN\n",
    "run_query_print(\"\"\"\n",
    "    SELECT title,\n",
    "           genres,\n",
    "           CONTAINS(SPLIT(genres, '|'), 'Comedy') AS is_comedy,\n",
    "           CONTAINS(SPLIT(genres, '|'), 'Drama') AS is_drama,\n",
    "           ELEMENT_AT(SPLIT(genres, '|'), 1) AS first_genre,\n",
    "           ARRAY_JOIN(SPLIT(genres, '|'), ' / ') AS genres_formatted\n",
    "    FROM movies\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM - transformacja elementów tablicy (lambda w SQL!)\n",
    "run_query_print(\"\"\"\n",
    "    SELECT title,\n",
    "           SPLIT(genres, '|') AS genres_array,\n",
    "           TRANSFORM(SPLIT(genres, '|'), x -> UPPER(x)) AS genres_upper,\n",
    "           FILTER(SPLIT(genres, '|'), x -> LENGTH(x) > 5) AS long_genres\n",
    "    FROM movies\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000001",
   "metadata": {},
   "source": [
    "## 5. Trino + dbt - transformacje SQL jako kod\n",
    "\n",
    "### Czym jest dbt (data build tool)?\n",
    "\n",
    "dbt to framework do **transformacji danych w SQL**, który dodaje:\n",
    "- **Modularność** - modele SQL referencujące inne modele\n",
    "- **Testowanie** - automatyczne testy danych (not null, unique, relationships)\n",
    "- **Dokumentacja** - auto-generowana dokumentacja z DAG\n",
    "- **Wersjonowanie** - modele SQL w Git\n",
    "- **Materializations** - tabele, widoki, incremental\n",
    "\n",
    "### dbt + Trino = potężna kombinacja\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────┐\n",
    "│                dbt Project                       │\n",
    "│                                                  │\n",
    "│  models/                                         │\n",
    "│  ├── staging/                                    │\n",
    "│  │   ├── stg_ratings.sql    ← SELECT z Trino    │\n",
    "│  │   └── stg_movies.sql     ← SELECT z Trino    │\n",
    "│  ├── intermediate/                               │\n",
    "│  │   └── int_movie_stats.sql                     │\n",
    "│  └── marts/                                      │\n",
    "│      ├── dim_movies.sql     ← tabela wymiarów   │\n",
    "│      └── fct_ratings.sql    ← tabela faktów     │\n",
    "│                                                  │\n",
    "│  Trino wykonuje SQL → wyniki do Hive/HDFS       │\n",
    "└─────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Przykładowy model dbt dla Trino:\n",
    "\n",
    "```sql\n",
    "-- models/staging/stg_ratings.sql\n",
    "-- dbt model: materialized as table in hive.analytics\n",
    "\n",
    "{{ config(\n",
    "    materialized='table',\n",
    "    schema='analytics'\n",
    ") }}\n",
    "\n",
    "SELECT\n",
    "    user_id,\n",
    "    movie_id,\n",
    "    rating,\n",
    "    rating_timestamp,\n",
    "    YEAR(rating_timestamp) AS rating_year\n",
    "FROM {{ source('movielens', 'ratings') }}\n",
    "WHERE rating IS NOT NULL\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- models/marts/fct_movie_stats.sql\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "SELECT\n",
    "    movie_id,\n",
    "    COUNT(*) AS num_ratings,\n",
    "    AVG(rating) AS avg_rating,\n",
    "    approx_percentile(rating, 0.5) AS median_rating\n",
    "FROM {{ ref('stg_ratings') }}\n",
    "GROUP BY movie_id\n",
    "```\n",
    "\n",
    "### Komendy dbt:\n",
    "```bash\n",
    "dbt run --target trino          # wykonaj wszystkie modele\n",
    "dbt test                        # uruchom testy\n",
    "dbt docs generate && dbt docs serve  # dokumentacja\n",
    "```\n",
    "\n",
    "**Uwaga:** To jest wyjaśnienie konceptu - nie implementujemy dbt w tym notebooku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symulacja dbt-style transformacji w czystym Trino SQL\n",
    "# Warstwa staging\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS memory.analytics\")\n",
    "\n",
    "# stg_ratings - oczyszczone dane\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS memory.analytics.stg_ratings AS\n",
    "    SELECT user_id,\n",
    "           movie_id,\n",
    "           rating,\n",
    "           rating_timestamp\n",
    "    FROM postgresql.movielens.ratings\n",
    "    WHERE rating IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# stg_movies\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS memory.analytics.stg_movies AS\n",
    "    SELECT movie_id,\n",
    "           title,\n",
    "           genres,\n",
    "           REGEXP_EXTRACT(title, '\\\\((\\\\d{4})\\\\)', 1) AS year_str\n",
    "    FROM postgresql.movielens.movies\n",
    "\"\"\")\n",
    "\n",
    "# Warstwa marts - movie stats\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS memory.analytics.fct_movie_stats AS\n",
    "    SELECT movie_id,\n",
    "           COUNT(*) AS num_ratings,\n",
    "           ROUND(AVG(rating), 2) AS avg_rating,\n",
    "           approx_percentile(rating, 0.5) AS median_rating\n",
    "    FROM memory.analytics.stg_ratings\n",
    "    GROUP BY movie_id\n",
    "\"\"\")\n",
    "\n",
    "print(\"dbt-style layers created in memory.analytics\")\n",
    "run_query_print(\"SHOW TABLES FROM memory.analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the marts layer\n",
    "run_query_print(\"\"\"\n",
    "    SELECT m.title,\n",
    "           m.year_str,\n",
    "           f.num_ratings,\n",
    "           f.avg_rating,\n",
    "           f.median_rating\n",
    "    FROM memory.analytics.fct_movie_stats f\n",
    "    JOIN memory.analytics.stg_movies m ON f.movie_id = m.movie_id\n",
    "    WHERE f.num_ratings > 10000\n",
    "    ORDER BY f.avg_rating DESC\n",
    "    LIMIT 15\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6000001",
   "metadata": {},
   "source": [
    "## 6. Materialized Views\n",
    "\n",
    "### Koncept\n",
    "\n",
    "Materialized view to **widok z cached wynikami** - zapytanie jest wykonywane raz, wynik zapisany fizycznie.\n",
    "\n",
    "```\n",
    "Zwykły VIEW:           SELECT → wykonuje query za każdym razem\n",
    "Materialized VIEW:     SELECT → zwraca zapisany wynik (szybko!)\n",
    "                       REFRESH → przelicza query i aktualizuje wynik\n",
    "```\n",
    "\n",
    "### W Trino:\n",
    "- Materialized views są obsługiwane przez **Hive connector**\n",
    "- Dane są fizycznie zapisane na HDFS jako Parquet\n",
    "- `REFRESH MATERIALIZED VIEW` przelicza dane\n",
    "- Trino może automatycznie użyć materialized view zamiast bazowej tabeli (rewriting)\n",
    "\n",
    "```sql\n",
    "-- Tworzenie materialized view (wymaga Hive connector)\n",
    "CREATE MATERIALIZED VIEW hive.analytics.mv_movie_stats AS\n",
    "SELECT movie_id,\n",
    "       COUNT(*) AS num_ratings,\n",
    "       AVG(rating) AS avg_rating\n",
    "FROM hive.movielens.ratings\n",
    "GROUP BY movie_id;\n",
    "\n",
    "-- Odświeżanie\n",
    "REFRESH MATERIALIZED VIEW hive.analytics.mv_movie_stats;\n",
    "\n",
    "-- Użycie - Trino może automatycznie skierować tu zapytania\n",
    "SELECT * FROM hive.analytics.mv_movie_stats\n",
    "WHERE num_ratings > 1000;\n",
    "```\n",
    "\n",
    "### Kiedy użyć materialized views?\n",
    "- Często powtarzane, kosztowne zapytania (dashboardy)\n",
    "- Agregaty na dużych tabelach\n",
    "- Dane zmieniają się rzadko (odświeżanie co godzinę/dzień)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symulacja materialized view z CTAS w memory\n",
    "# (prawdziwe materialized views wymagają Hive connector)\n",
    "\n",
    "# \"Materialized view\" - movie stats\n",
    "start = time.time()\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS memory.analytics.mv_genre_stats\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE memory.analytics.mv_genre_stats AS\n",
    "    WITH genre_exploded AS (\n",
    "        SELECT r.movie_id, r.rating, genre\n",
    "        FROM postgresql.movielens.ratings r\n",
    "        JOIN postgresql.movielens.movies m ON r.movie_id = m.movie_id\n",
    "        CROSS JOIN UNNEST(SPLIT(m.genres, '|')) AS t(genre)\n",
    "    )\n",
    "    SELECT genre,\n",
    "           COUNT(*) AS total_ratings,\n",
    "           approx_distinct(movie_id) AS unique_movies,\n",
    "           ROUND(AVG(rating), 3) AS avg_rating,\n",
    "           approx_percentile(rating, 0.5) AS median_rating\n",
    "    FROM genre_exploded\n",
    "    WHERE genre != '(no genres listed)'\n",
    "    GROUP BY genre\n",
    "\"\"\")\n",
    "create_time = time.time() - start\n",
    "print(f\"Materialized view created in {create_time:.2f}s\")\n",
    "\n",
    "# Szybkie zapytanie do materialized view\n",
    "start = time.time()\n",
    "df = run_query_print(\"\"\"\n",
    "    SELECT * FROM memory.analytics.mv_genre_stats\n",
    "    ORDER BY total_ratings DESC\n",
    "\"\"\")\n",
    "query_time = time.time() - start\n",
    "print(f\"Query time: {query_time:.3f}s (vs {create_time:.2f}s for full computation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7000001",
   "metadata": {},
   "source": [
    "## 7. Partycjonowanie i bucketing w Hive Connector\n",
    "\n",
    "### Partycjonowanie\n",
    "Dane na HDFS mogą być **partycjonowane** - fizycznie podzielone na podkatalogi.\n",
    "\n",
    "```\n",
    "hdfs://namenode:9000/data/movielens/ratings/\n",
    "├── year=2010/\n",
    "│   ├── part-00000.parquet\n",
    "│   └── part-00001.parquet\n",
    "├── year=2011/\n",
    "│   └── part-00000.parquet\n",
    "└── year=2015/\n",
    "    └── part-00000.parquet\n",
    "```\n",
    "\n",
    "Trino automatycznie stosuje **partition pruning** - czyta tylko potrzebne partycje.\n",
    "\n",
    "### Tworzenie partycjonowanej tabeli w Hive z Trino:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE hive.movielens.ratings_partitioned (\n",
    "    user_id INTEGER,\n",
    "    movie_id INTEGER,\n",
    "    rating DOUBLE,\n",
    "    rating_timestamp TIMESTAMP\n",
    ") WITH (\n",
    "    format = 'PARQUET',\n",
    "    partitioned_by = ARRAY['rating_year'],\n",
    "    bucketed_by = ARRAY['movie_id'],\n",
    "    bucket_count = 16\n",
    ");\n",
    "```\n",
    "\n",
    "### Bucketing\n",
    "Bucketing dzieli dane na stałą liczbę plików wg hash klucza.\n",
    "Optymalizuje JOIN i GROUP BY na tym kluczu - Trino wie, które pliki łączyć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdź partycje istniejącej tabeli hive\n",
    "# (jeśli tabela była zapisana z partycjonowaniem przez Spark)\n",
    "try:\n",
    "    run_query_print(\"\"\"\n",
    "        SELECT * FROM hive.movielens.\"ratings$partitions\"\n",
    "        LIMIT 20\n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(f\"Partitions query: {e}\")\n",
    "    print(\"Tabela może nie być partycjonowana lub nie istnieć.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Właściwości tabeli hive\n",
    "try:\n",
    "    run_query_print(\"\"\"\n",
    "        SHOW CREATE TABLE hive.movielens.ratings\n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(f\"Show create table: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8000001",
   "metadata": {},
   "source": [
    "## 8. Optymalizacja zapytań: Predicate Pushdown i Partition Pruning\n",
    "\n",
    "### Predicate Pushdown\n",
    "Trino przesuwa filtry (WHERE) do źródła danych:\n",
    "- **PostgreSQL connector**: filtr staje się częścią SQL wysyłanego do PostgreSQL\n",
    "- **Hive connector**: filtr jest stosowany przy odczycie Parquet (row group filtering)\n",
    "\n",
    "```\n",
    "Bez pushdown:   PostgreSQL → [ALL rows] → Trino → FILTER\n",
    "Z pushdown:     PostgreSQL → FILTER → [filtered rows] → Trino\n",
    "```\n",
    "\n",
    "### Partition Pruning\n",
    "Trino czyta tylko partycje pasujące do filtra WHERE:\n",
    "```sql\n",
    "-- Czyta TYLKO partycję year=2015 (nie skanuje reszty)\n",
    "SELECT * FROM hive.movielens.ratings_partitioned\n",
    "WHERE year = 2015\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstracja predicate pushdown - sprawdź EXPLAIN\n",
    "explain_result = run_query(\"\"\"\n",
    "    EXPLAIN\n",
    "    SELECT user_id, movie_id, rating\n",
    "    FROM postgresql.movielens.ratings\n",
    "    WHERE user_id = 42 AND rating >= 4.0\n",
    "\"\"\")\n",
    "\n",
    "for _, row in explain_result.iterrows():\n",
    "    print(row.iloc[0])\n",
    "\n",
    "print(\"\\n--- Szukaj 'constraint' lub 'pushdown' w planie ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: pushdown vs no pushdown (symulacja)\n",
    "# Z pushdown - filtr na user_id przesunięty do PostgreSQL\n",
    "start = time.time()\n",
    "run_query(\"\"\"\n",
    "    SELECT COUNT(*), AVG(rating)\n",
    "    FROM postgresql.movielens.ratings\n",
    "    WHERE user_id = 42\n",
    "\"\"\")\n",
    "pushdown_time = time.time() - start\n",
    "\n",
    "# Bez efektywnego pushdown - obliczenie po stronie Trino\n",
    "start = time.time()\n",
    "run_query(\"\"\"\n",
    "    SELECT COUNT(*), AVG(rating)\n",
    "    FROM (\n",
    "        SELECT * FROM postgresql.movielens.ratings\n",
    "    ) sub\n",
    "    WHERE user_id = 42\n",
    "\"\"\")\n",
    "no_pushdown_time = time.time() - start\n",
    "\n",
    "print(f\"Z pushdown:    {pushdown_time:.3f}s\")\n",
    "print(f\"Bez pushdown:  {no_pushdown_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9000001",
   "metadata": {},
   "source": [
    "## 9. Performance Tuning: Session Properties i Resource Groups\n",
    "\n",
    "### Session Properties\n",
    "Trino pozwala dostroić zachowanie per-query lub per-session.\n",
    "\n",
    "### Resource Groups\n",
    "Resource groups kontrolują alokację zasobów (CPU, pamięć) między zapytaniami.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"rootGroups\": [\n",
    "    {\n",
    "      \"name\": \"analytics\",\n",
    "      \"maxQueued\": 100,\n",
    "      \"hardConcurrencyLimit\": 10,\n",
    "      \"softMemoryLimit\": \"80%\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"etl\",\n",
    "      \"maxQueued\": 10,\n",
    "      \"hardConcurrencyLimit\": 3,\n",
    "      \"softMemoryLimit\": \"20%\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dostępne session properties\n",
    "run_query_print(\"\"\"\n",
    "    SHOW SESSION\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ustawienie session properties\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Join distribution type: AUTOMATIC, BROADCAST, PARTITIONED\n",
    "cursor.execute(\"SET SESSION join_distribution_type = 'AUTOMATIC'\")\n",
    "\n",
    "# Join reordering: AUTOMATIC, ELIMINATE_CROSS_JOINS, NONE\n",
    "cursor.execute(\"SET SESSION join_reordering_strategy = 'AUTOMATIC'\")\n",
    "\n",
    "# Optymalizacja hash aggregation\n",
    "cursor.execute(\"SET SESSION task_concurrency = 8\")\n",
    "\n",
    "print(\"Session properties set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wpływ join_distribution_type na plan zapytania\n",
    "for dist_type in ['BROADCAST', 'PARTITIONED']:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SET SESSION join_distribution_type = '{dist_type}'\")\n",
    "    \n",
    "    explain = run_query(f\"\"\"\n",
    "        EXPLAIN (TYPE DISTRIBUTED)\n",
    "        SELECT m.title, COUNT(*) AS cnt\n",
    "        FROM postgresql.movielens.ratings r\n",
    "        JOIN postgresql.movielens.movies m ON r.movie_id = m.movie_id\n",
    "        GROUP BY m.title\n",
    "        ORDER BY cnt DESC\n",
    "        LIMIT 10\n",
    "    \"\"\")\n",
    "    \n",
    "    print(f\"\\n=== join_distribution_type = {dist_type} ===\")\n",
    "    for _, row in explain.iterrows():\n",
    "        print(row.iloc[0])\n",
    "\n",
    "# Reset to AUTOMATIC\n",
    "cursor.execute(\"SET SESSION join_distribution_type = 'AUTOMATIC'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9000002",
   "metadata": {},
   "source": [
    "### Najważniejsze session properties:\n",
    "\n",
    "| Property | Wartości | Opis |\n",
    "|----------|---------|------|\n",
    "| `join_distribution_type` | AUTOMATIC, BROADCAST, PARTITIONED | Strategia join |\n",
    "| `join_reordering_strategy` | AUTOMATIC, NONE | Czy optimizer zmienia kolejność joinów |\n",
    "| `task_concurrency` | liczba | Paralelizm per task |\n",
    "| `query_max_memory` | np. '4GB' | Limit pamięci per query |\n",
    "| `query_max_execution_time` | np. '10m' | Timeout query |\n",
    "| `optimize_hash_generation` | true/false | Optymalizacja hash joinów |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10000001",
   "metadata": {},
   "source": [
    "## Zadanie 1\n",
    "\n",
    "Przepisz zapytania z **notebook 05 (Spark SQL)** na Trino SQL.\n",
    "\n",
    "Przepisz następujące zapytania:\n",
    "\n",
    "1. **ROW_NUMBER** - top 3 najwyżej ocenianych filmów per użytkownik (user_id <= 10)\n",
    "2. **LAG** - zmiana oceny w czasie dla user_id = 42\n",
    "3. **CTE z window function** - profil użytkownika z kategorią aktywności i ranking w kategorii\n",
    "4. **NTILE** - podział użytkowników na decyle po średniej ocenie, z approx_distinct zamiast COUNT(DISTINCT)\n",
    "\n",
    "Porównaj składnię - co jest takie samo, co inne?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n",
    "\n",
    "# 1. ROW_NUMBER - top 3 per user\n",
    "run_query_print(\"\"\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LAG - zmiana oceny w czasie\n",
    "run_query_print(\"\"\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. CTE z window function\n",
    "run_query_print(\"\"\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. NTILE z approx_distinct\n",
    "run_query_print(\"\"\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11000001",
   "metadata": {},
   "source": [
    "## Zadanie końcowe\n",
    "\n",
    "Zbuduj **raport analityczny** w Trino łączący zaawansowane techniki:\n",
    "\n",
    "### Część 1: Top filmy per gatunek per dekada\n",
    "- Użyj `UNNEST(SPLIT(genres, '|'))` do rozbicia gatunków\n",
    "- Wyciągnij rok z tytułu: `REGEXP_EXTRACT(title, '\\(([0-9]{4})\\)', 1)`\n",
    "- Oblicz dekadę: `FLOOR(CAST(year AS INTEGER) / 10) * 10`\n",
    "- Użyj `ROW_NUMBER()` do znalezienia top 3 filmów per gatunek per dekada\n",
    "- Filtruj: minimum 100 ocen per film\n",
    "\n",
    "### Część 2: Segmentacja użytkowników\n",
    "- Podziel użytkowników na segmenty po aktywności (power/active/casual/rare)\n",
    "- Dla każdego segmentu oblicz z `approx_percentile`: medianę, p25, p75 średniej oceny\n",
    "- Dodaj `approx_distinct` gatunków ocenianych per segment\n",
    "\n",
    "### Część 3: Trending analysis\n",
    "- Użyj `LAG()` do porównania średniej oceny filmu z poprzednią dekadą\n",
    "- Znajdź gatunki, których popularność (liczba ocen) rośnie najszybciej\n",
    "- Użyj `PERCENT_RANK()` do rankingu trendów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n",
    "\n",
    "# Część 1: Top filmy per gatunek per dekada\n",
    "run_query_print(\"\"\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Część 2: Segmentacja użytkowników\n",
    "run_query_print(\"\"\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Część 3: Trending analysis\n",
    "run_query_print(\"\"\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "cursor = conn.cursor()\n",
    "for table in ['stg_ratings', 'stg_movies', 'fct_movie_stats', 'mv_genre_stats']:\n",
    "    try:\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS memory.analytics.{table}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not drop {table}: {e}\")\n",
    "\n",
    "conn.close()\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
