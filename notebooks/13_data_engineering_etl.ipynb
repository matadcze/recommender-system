{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1000001",
   "metadata": {},
   "source": [
    "# 13 - Data Engineering & ETL Pipelines\n",
    "\n",
    "Budowanie produkcyjnych pipeline'ów przetwarzania danych.\n",
    "\n",
    "**Tematy:**\n",
    "- ETL pipeline: Raw → Clean → Transform → Load\n",
    "- Data quality checks - walidacja danych\n",
    "- Delta Lake - ACID, time travel, schema evolution, MERGE\n",
    "- SCD Type 2 - śledzenie zmian w danych\n",
    "- Medallion architecture (Bronze → Silver → Gold)\n",
    "- Zapis do wielu formatów i systemów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"13_Data_Engineering\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \"org.postgresql:postgresql:42.7.1,\"\n",
    "            \"io.delta:delta-spark_2.12:3.3.1\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .config(\"spark.executor.memory\", \"7g\") \\\n",
    "    .config(\"spark.driver.host\", \"recommender-jupyter\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/recommender\"\n",
    "properties = {\n",
    "    \"user\": \"recommender\",\n",
    "    \"password\": \"recommender\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Katalogi\n",
    "BRONZE_PATH = \"/tmp/datalake/bronze\"\n",
    "SILVER_PATH = \"/tmp/datalake/silver\"\n",
    "GOLD_PATH = \"/tmp/datalake/gold\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2000001",
   "metadata": {},
   "source": [
    "## 2. Medallion Architecture\n",
    "\n",
    "Standardowy wzorzec organizacji danych w data lake:\n",
    "\n",
    "```\n",
    "Bronze (Raw)     → Silver (Clean)      → Gold (Aggregated)\n",
    "─────────────      ───────────────        ─────────────────\n",
    "Surowe dane        Oczyszczone           Gotowe do analiz\n",
    "Bez zmian          Deduplikacja          Agregaty\n",
    "Append-only        Type casting          Metryki biznesowe\n",
    "Schema-on-read     Walidacja             Feature store\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000001",
   "metadata": {},
   "source": [
    "## 3. Bronze Layer - surowe dane\n",
    "\n",
    "Załaduj dane as-is, dodaj metadane ingestii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Załaduj surowe dane z PostgreSQL\n",
    "ratings_raw = spark.read.jdbc(\n",
    "    jdbc_url, \"movielens.ratings\", properties=properties,\n",
    "    column=\"user_id\", lowerBound=1, upperBound=300000, numPartitions=10\n",
    ")\n",
    "movies_raw = spark.read.jdbc(jdbc_url, \"movielens.movies\", properties=properties)\n",
    "\n",
    "# Dodaj metadane ingestii\n",
    "ratings_bronze = ratings_raw \\\n",
    "    .withColumn(\"_ingestion_timestamp\", current_timestamp()) \\\n",
    "    .withColumn(\"_source\", lit(\"postgresql\")) \\\n",
    "    .withColumn(\"_batch_id\", lit(\"batch_001\"))\n",
    "\n",
    "movies_bronze = movies_raw \\\n",
    "    .withColumn(\"_ingestion_timestamp\", current_timestamp()) \\\n",
    "    .withColumn(\"_source\", lit(\"postgresql\")) \\\n",
    "    .withColumn(\"_batch_id\", lit(\"batch_001\"))\n",
    "\n",
    "# Zapisz do Bronze (Parquet)\n",
    "ratings_bronze.write.mode(\"overwrite\").parquet(f\"{BRONZE_PATH}/ratings\")\n",
    "movies_bronze.write.mode(\"overwrite\").parquet(f\"{BRONZE_PATH}/movies\")\n",
    "\n",
    "print(f\"Bronze ratings: {ratings_bronze.count()} rows\")\n",
    "print(f\"Bronze movies: {movies_bronze.count()} rows\")\n",
    "ratings_bronze.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4000001",
   "metadata": {},
   "source": [
    "## 4. Data Quality Checks\n",
    "\n",
    "Przed transformacją do Silver - walidacja jakości danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQualityChecker:\n",
    "    \"\"\"Framework do walidacji jakości danych.\"\"\"\n",
    "    \n",
    "    def __init__(self, df, name):\n",
    "        self.df = df\n",
    "        self.name = name\n",
    "        self.results = []\n",
    "    \n",
    "    def check_not_null(self, columns):\n",
    "        \"\"\"Sprawdź czy kolumny nie mają nulli.\"\"\"\n",
    "        for col_name in columns:\n",
    "            null_count = self.df.filter(col(col_name).isNull()).count()\n",
    "            total = self.df.count()\n",
    "            passed = null_count == 0\n",
    "            self.results.append({\n",
    "                \"check\": f\"not_null({col_name})\",\n",
    "                \"passed\": passed,\n",
    "                \"detail\": f\"{null_count}/{total} nulls ({null_count/total*100:.2f}%)\"\n",
    "            })\n",
    "        return self\n",
    "    \n",
    "    def check_range(self, column, min_val, max_val):\n",
    "        \"\"\"Sprawdź czy wartości są w zakresie.\"\"\"\n",
    "        out_of_range = self.df.filter(\n",
    "            (col(column) < min_val) | (col(column) > max_val)\n",
    "        ).count()\n",
    "        passed = out_of_range == 0\n",
    "        self.results.append({\n",
    "            \"check\": f\"range({column}, {min_val}-{max_val})\",\n",
    "            \"passed\": passed,\n",
    "            \"detail\": f\"{out_of_range} out of range\"\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def check_unique(self, columns):\n",
    "        \"\"\"Sprawdź unikalność kombinacji kolumn.\"\"\"\n",
    "        total = self.df.count()\n",
    "        distinct = self.df.select(columns).distinct().count()\n",
    "        duplicates = total - distinct\n",
    "        passed = duplicates == 0\n",
    "        self.results.append({\n",
    "            \"check\": f\"unique({','.join(columns)})\",\n",
    "            \"passed\": passed,\n",
    "            \"detail\": f\"{duplicates} duplicates\"\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def check_referential_integrity(self, column, ref_df, ref_column):\n",
    "        \"\"\"Sprawdź integralność referencyjną.\"\"\"\n",
    "        orphans = self.df.join(\n",
    "            ref_df.select(col(ref_column).alias(\"_ref\")),\n",
    "            col(column) == col(\"_ref\"),\n",
    "            \"left_anti\"\n",
    "        ).count()\n",
    "        passed = orphans == 0\n",
    "        self.results.append({\n",
    "            \"check\": f\"ref_integrity({column})\",\n",
    "            \"passed\": passed,\n",
    "            \"detail\": f\"{orphans} orphan records\"\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def report(self):\n",
    "        \"\"\"Wyświetl raport.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Data Quality Report: {self.name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        all_passed = True\n",
    "        for r in self.results:\n",
    "            status = \"PASS\" if r['passed'] else \"FAIL\"\n",
    "            if not r['passed']:\n",
    "                all_passed = False\n",
    "            print(f\"  [{status}] {r['check']}: {r['detail']}\")\n",
    "        print(f\"\\nOverall: {'ALL PASSED' if all_passed else 'FAILURES DETECTED'}\")\n",
    "        return all_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odczytaj bronze\n",
    "ratings_b = spark.read.parquet(f\"{BRONZE_PATH}/ratings\")\n",
    "movies_b = spark.read.parquet(f\"{BRONZE_PATH}/movies\")\n",
    "\n",
    "# Walidacja ratings\n",
    "ratings_ok = DataQualityChecker(ratings_b, \"ratings_bronze\") \\\n",
    "    .check_not_null([\"user_id\", \"movie_id\", \"rating\"]) \\\n",
    "    .check_range(\"rating\", 0.5, 5.0) \\\n",
    "    .check_range(\"user_id\", 1, 999999) \\\n",
    "    .check_unique([\"user_id\", \"movie_id\"]) \\\n",
    "    .check_referential_integrity(\"movie_id\", movies_b, \"movie_id\") \\\n",
    "    .report()\n",
    "\n",
    "# Walidacja movies\n",
    "movies_ok = DataQualityChecker(movies_b, \"movies_bronze\") \\\n",
    "    .check_not_null([\"movie_id\", \"title\", \"genres\"]) \\\n",
    "    .check_unique([\"movie_id\"]) \\\n",
    "    .report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000001",
   "metadata": {},
   "source": [
    "## 5. Silver Layer - oczyszczone dane\n",
    "\n",
    "Transformacje: czyszczenie, type casting, deduplication, enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silver - ratings\n",
    "ratings_silver = ratings_b \\\n",
    "    .select(\"user_id\", \"movie_id\", \"rating\", \"rating_timestamp\") \\\n",
    "    .dropDuplicates([\"user_id\", \"movie_id\"]) \\\n",
    "    .filter(col(\"rating\").between(0.5, 5.0)) \\\n",
    "    .filter(col(\"user_id\").isNotNull() & col(\"movie_id\").isNotNull()) \\\n",
    "    .withColumn(\"rating_date\", to_date(col(\"rating_timestamp\"))) \\\n",
    "    .withColumn(\"rating_year\", year(col(\"rating_timestamp\"))) \\\n",
    "    .withColumn(\"rating_month\", month(col(\"rating_timestamp\"))) \\\n",
    "    .withColumn(\"rating_hour\", hour(col(\"rating_timestamp\"))) \\\n",
    "    .withColumn(\"is_positive\", (col(\"rating\") >= 4.0).cast(\"int\")) \\\n",
    "    .withColumn(\"_processed_at\", current_timestamp())\n",
    "\n",
    "# Silver - movies (enriched)\n",
    "movies_silver = movies_b \\\n",
    "    .select(\"movie_id\", \"title\", \"genres\") \\\n",
    "    .dropDuplicates([\"movie_id\"]) \\\n",
    "    .withColumn(\"year\", regexp_extract(col(\"title\"), r\"\\((\\d{4})\\)\", 1).cast(\"int\")) \\\n",
    "    .withColumn(\"clean_title\", regexp_replace(col(\"title\"), r\"\\s*\\(\\d{4}\\)\\s*$\", \"\")) \\\n",
    "    .withColumn(\"genre_array\", split(col(\"genres\"), \"\\\\|\")) \\\n",
    "    .withColumn(\"num_genres\", size(split(col(\"genres\"), \"\\\\|\"))) \\\n",
    "    .withColumn(\"primary_genre\", element_at(split(col(\"genres\"), \"\\\\|\"), 1)) \\\n",
    "    .withColumn(\"decade\", (floor(col(\"year\") / 10) * 10).cast(\"int\")) \\\n",
    "    .withColumn(\"_processed_at\", current_timestamp())\n",
    "\n",
    "# Zapisz Silver\n",
    "ratings_silver.write.mode(\"overwrite\") \\\n",
    "    .partitionBy(\"rating_year\") \\\n",
    "    .parquet(f\"{SILVER_PATH}/ratings\")\n",
    "\n",
    "movies_silver.write.mode(\"overwrite\") \\\n",
    "    .parquet(f\"{SILVER_PATH}/movies\")\n",
    "\n",
    "print(f\"Silver ratings: {ratings_silver.count()} rows\")\n",
    "print(f\"Silver movies: {movies_silver.count()} rows\")\n",
    "ratings_silver.show(3)\n",
    "movies_silver.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6000001",
   "metadata": {},
   "source": [
    "## 6. Gold Layer - agregaty biznesowe\n",
    "\n",
    "Gotowe do konsumpcji przez analizy, dashboardy, modele ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odczytaj Silver\n",
    "ratings_s = spark.read.parquet(f\"{SILVER_PATH}/ratings\")\n",
    "movies_s = spark.read.parquet(f\"{SILVER_PATH}/movies\")\n",
    "\n",
    "# Gold: Movie Stats - statystyki per film\n",
    "gold_movie_stats = ratings_s.groupBy(\"movie_id\").agg(\n",
    "    count(\"*\").alias(\"total_ratings\"),\n",
    "    countDistinct(\"user_id\").alias(\"unique_raters\"),\n",
    "    round(avg(\"rating\"), 3).alias(\"avg_rating\"),\n",
    "    round(stddev(\"rating\"), 3).alias(\"std_rating\"),\n",
    "    round(avg(\"is_positive\"), 3).alias(\"positive_rate\"),\n",
    "    min(\"rating_date\").alias(\"first_rating_date\"),\n",
    "    max(\"rating_date\").alias(\"last_rating_date\")\n",
    ").join(movies_s, \"movie_id\")\n",
    "\n",
    "# Wilson score for ranking (lower bound of confidence interval)\n",
    "@udf(\"double\")\n",
    "def wilson_score(positive, total):\n",
    "    import math\n",
    "    if total == 0: return 0.0\n",
    "    z = 1.96\n",
    "    p = positive / total\n",
    "    denom = 1 + z * z / total\n",
    "    centre = p + z * z / (2 * total)\n",
    "    delta = z * math.sqrt((p * (1 - p) + z * z / (4 * total)) / total)\n",
    "    return float((centre - delta) / denom)\n",
    "\n",
    "gold_movie_stats = gold_movie_stats.withColumn(\n",
    "    \"wilson_score\",\n",
    "    round(wilson_score(\n",
    "        (col(\"positive_rate\") * col(\"total_ratings\")).cast(\"double\"),\n",
    "        col(\"total_ratings\").cast(\"double\")\n",
    "    ), 4)\n",
    ")\n",
    "\n",
    "gold_movie_stats.write.mode(\"overwrite\").parquet(f\"{GOLD_PATH}/movie_stats\")\n",
    "\n",
    "print(\"Gold Movie Stats - Top 15 (Wilson Score):\")\n",
    "gold_movie_stats.filter(col(\"total_ratings\") >= 100) \\\n",
    "    .orderBy(desc(\"wilson_score\")) \\\n",
    "    .select(\"title\", \"total_ratings\", \"avg_rating\", \"positive_rate\", \"wilson_score\") \\\n",
    "    .show(15, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold: User Profiles - profil każdego użytkownika\n",
    "gold_user_profiles = ratings_s.groupBy(\"user_id\").agg(\n",
    "    count(\"*\").alias(\"total_ratings\"),\n",
    "    round(avg(\"rating\"), 2).alias(\"avg_rating\"),\n",
    "    round(stddev(\"rating\"), 2).alias(\"rating_variance\"),\n",
    "    sum(\"is_positive\").alias(\"positive_count\"),\n",
    "    countDistinct(\"movie_id\").alias(\"unique_movies\"),\n",
    "    min(\"rating_date\").alias(\"first_activity\"),\n",
    "    max(\"rating_date\").alias(\"last_activity\"),\n",
    "    countDistinct(\"rating_year\").alias(\"active_years\")\n",
    ").withColumn(\n",
    "    \"user_segment\",\n",
    "    when(col(\"total_ratings\") >= 1000, \"power_user\")\n",
    "    .when(col(\"total_ratings\") >= 100, \"active\")\n",
    "    .when(col(\"total_ratings\") >= 20, \"casual\")\n",
    "    .otherwise(\"new\")\n",
    ").withColumn(\n",
    "    \"positivity_rate\",\n",
    "    round(col(\"positive_count\") / col(\"total_ratings\"), 2)\n",
    ")\n",
    "\n",
    "gold_user_profiles.write.mode(\"overwrite\").parquet(f\"{GOLD_PATH}/user_profiles\")\n",
    "\n",
    "print(\"User segment distribution:\")\n",
    "gold_user_profiles.groupBy(\"user_segment\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    round(avg(\"avg_rating\"), 2).alias(\"segment_avg_rating\"),\n",
    "    round(avg(\"total_ratings\"), 0).alias(\"avg_num_ratings\")\n",
    ").orderBy(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold: Genre Trends - trendy gatunków w czasie\n",
    "genre_exploded = ratings_s.join(movies_s.select(\"movie_id\", \"genre_array\"), \"movie_id\") \\\n",
    "    .withColumn(\"genre\", explode(col(\"genre_array\")))\n",
    "\n",
    "gold_genre_trends = genre_exploded.groupBy(\"genre\", \"rating_year\").agg(\n",
    "    count(\"*\").alias(\"num_ratings\"),\n",
    "    round(avg(\"rating\"), 2).alias(\"avg_rating\"),\n",
    "    countDistinct(\"movie_id\").alias(\"unique_movies\"),\n",
    "    countDistinct(\"user_id\").alias(\"unique_users\")\n",
    ")\n",
    "\n",
    "gold_genre_trends.write.mode(\"overwrite\") \\\n",
    "    .partitionBy(\"genre\") \\\n",
    "    .parquet(f\"{GOLD_PATH}/genre_trends\")\n",
    "\n",
    "print(\"Genre trends (Drama, last 5 years):\")\n",
    "gold_genre_trends.filter(\n",
    "    (col(\"genre\") == \"Drama\") & (col(\"rating_year\") >= 2010)\n",
    ").orderBy(\"rating_year\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6000002",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "Stwórz Gold table: `gold_recommendations_input` z następującymi kolumnami per user:\n",
    "- user_id, avg_rating, total_ratings, user_segment\n",
    "- top_3_genres (3 najczęściej oceniane gatunki)\n",
    "- avg_movie_year (średni rok filmów, które ocenił)\n",
    "\n",
    "Ten DataFrame potem mógłby zasilać model rekomendacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7000001",
   "metadata": {},
   "source": [
    "## 7. Delta Lake\n",
    "\n",
    "Delta Lake dodaje do data lake:\n",
    "- **ACID transactions** - atomowe zapisy\n",
    "- **Schema enforcement** - walidacja schematu\n",
    "- **Time travel** - dostęp do poprzednich wersji danych\n",
    "- **MERGE** (upsert) - wstaw lub zaktualizuj\n",
    "- **Z-ordering** - optymalizacja layoutu plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "DELTA_PATH = \"/tmp/datalake/delta\"\n",
    "\n",
    "# Zapisz jako Delta\n",
    "movies_s = spark.read.parquet(f\"{SILVER_PATH}/movies\")\n",
    "\n",
    "movies_s.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(f\"{DELTA_PATH}/movies\")\n",
    "\n",
    "print(\"Delta table created\")\n",
    "\n",
    "# Odczytaj Delta\n",
    "delta_movies = spark.read.format(\"delta\").load(f\"{DELTA_PATH}/movies\")\n",
    "delta_movies.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE (upsert) - aktualizuj istniejące, wstaw nowe\n",
    "# Symulujmy aktualizację: zmiana gatunku kilku filmów + nowy film\n",
    "\n",
    "updates = spark.createDataFrame([\n",
    "    # Aktualizacja istniejącego\n",
    "    (1, \"Toy Story (1995)\", \"Adventure|Animation|Children|Comedy|Fantasy|Family\",\n",
    "     1995, \"Toy Story\", None, 6, \"Adventure\", 1990, None),\n",
    "    # Nowy film\n",
    "    (999999, \"Test Movie (2025)\", \"Sci-Fi|Action\",\n",
    "     2025, \"Test Movie\", None, 2, \"Sci-Fi\", 2020, None)\n",
    "], movies_s.schema)\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, f\"{DELTA_PATH}/movies\")\n",
    "\n",
    "delta_table.alias(\"target\") \\\n",
    "    .merge(\n",
    "        updates.alias(\"source\"),\n",
    "        \"target.movie_id = source.movie_id\"\n",
    "    ) \\\n",
    "    .whenMatchedUpdateAll() \\\n",
    "    .whenNotMatchedInsertAll() \\\n",
    "    .execute()\n",
    "\n",
    "# Sprawdź\n",
    "spark.read.format(\"delta\").load(f\"{DELTA_PATH}/movies\") \\\n",
    "    .filter(col(\"movie_id\").isin(1, 999999)) \\\n",
    "    .select(\"movie_id\", \"title\", \"genres\", \"num_genres\") \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Travel - dostęp do poprzednich wersji\n",
    "\n",
    "# Historia wersji\n",
    "delta_table.history().select(\"version\", \"timestamp\", \"operation\", \"operationMetrics\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odczytaj starszą wersję (przed MERGE)\n",
    "old_version = spark.read.format(\"delta\") \\\n",
    "    .option(\"versionAsOf\", 0) \\\n",
    "    .load(f\"{DELTA_PATH}/movies\")\n",
    "\n",
    "current_version = spark.read.format(\"delta\").load(f\"{DELTA_PATH}/movies\")\n",
    "\n",
    "print(f\"Wersja 0 (przed MERGE): {old_version.count()} filmów\")\n",
    "print(f\"Wersja aktualna: {current_version.count()} filmów\")\n",
    "\n",
    "# Toy Story w starej wersji\n",
    "print(\"\\nToy Story - wersja 0 (oryginał):\")\n",
    "old_version.filter(col(\"movie_id\") == 1).select(\"title\", \"genres\", \"num_genres\").show(truncate=False)\n",
    "\n",
    "print(\"Toy Story - wersja aktualna (po MERGE):\")\n",
    "current_version.filter(col(\"movie_id\") == 1).select(\"title\", \"genres\", \"num_genres\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema Evolution - dodawanie kolumn\n",
    "# Delta domyślnie blokuje zmiany schematu\n",
    "\n",
    "enriched_movies = current_version \\\n",
    "    .withColumn(\"popularity_tier\", lit(\"unknown\"))\n",
    "\n",
    "# Z mergeSchema = true pozwala na dodanie nowej kolumny\n",
    "enriched_movies.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .save(f\"{DELTA_PATH}/movies\")\n",
    "\n",
    "print(\"Schema po ewolucji:\")\n",
    "spark.read.format(\"delta\").load(f\"{DELTA_PATH}/movies\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8000001",
   "metadata": {},
   "source": [
    "## 8. SCD Type 2 - Slowly Changing Dimensions\n",
    "\n",
    "Śledzenie historii zmian rekordu.\n",
    "\n",
    "Każdy rekord ma:\n",
    "- `effective_from` - od kiedy ten wiersz jest aktualny\n",
    "- `effective_to` - do kiedy (null = aktualny)\n",
    "- `is_current` - czy to aktualna wersja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Inicjalizuj tabelę SCD2\n",
    "movies_scd = movies_s \\\n",
    "    .select(\"movie_id\", \"title\", \"genres\", \"primary_genre\") \\\n",
    "    .withColumn(\"effective_from\", lit(datetime(2020, 1, 1)).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"effective_to\", lit(None).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"is_current\", lit(True))\n",
    "\n",
    "movies_scd.write.format(\"delta\").mode(\"overwrite\").save(f\"{DELTA_PATH}/movies_scd2\")\n",
    "\n",
    "print(f\"SCD2 initial: {movies_scd.count()} rows\")\n",
    "movies_scd.filter(col(\"movie_id\") == 1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symuluj aktualizację: Toy Story zmienia gatunek\n",
    "updates_scd = spark.createDataFrame([\n",
    "    (1, \"Toy Story (1995)\", \"Adventure|Animation|Children|Comedy|Fantasy|Family\", \"Adventure\"),\n",
    "    (2, \"Jumanji (1995)\", \"Adventure|Children|Fantasy|Action\", \"Adventure\"),\n",
    "], [\"movie_id\", \"title\", \"genres\", \"primary_genre\"])\n",
    "\n",
    "now = current_timestamp()\n",
    "\n",
    "# SCD Type 2 MERGE:\n",
    "# 1. Zamknij stary rekord (is_current = false, effective_to = now)\n",
    "# 2. Wstaw nowy rekord (is_current = true, effective_from = now)\n",
    "\n",
    "delta_scd = DeltaTable.forPath(spark, f\"{DELTA_PATH}/movies_scd2\")\n",
    "\n",
    "# Krok 1: Zamknij stare rekordy\n",
    "delta_scd.alias(\"target\") \\\n",
    "    .merge(\n",
    "        updates_scd.alias(\"source\"),\n",
    "        \"target.movie_id = source.movie_id AND target.is_current = true\"\n",
    "    ) \\\n",
    "    .whenMatchedUpdate(set={\n",
    "        \"is_current\": lit(False),\n",
    "        \"effective_to\": now\n",
    "    }) \\\n",
    "    .execute()\n",
    "\n",
    "# Krok 2: Wstaw nowe wersje\n",
    "new_records = updates_scd \\\n",
    "    .withColumn(\"effective_from\", now) \\\n",
    "    .withColumn(\"effective_to\", lit(None).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"is_current\", lit(True))\n",
    "\n",
    "new_records.write.format(\"delta\").mode(\"append\").save(f\"{DELTA_PATH}/movies_scd2\")\n",
    "\n",
    "# Sprawdź historię Toy Story\n",
    "print(\"Historia Toy Story (SCD Type 2):\")\n",
    "spark.read.format(\"delta\").load(f\"{DELTA_PATH}/movies_scd2\") \\\n",
    "    .filter(col(\"movie_id\") == 1) \\\n",
    "    .orderBy(\"effective_from\") \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9000001",
   "metadata": {},
   "source": [
    "## 9. Zapis do wielu systemów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odczytaj Gold stats\n",
    "movie_stats = spark.read.parquet(f\"{GOLD_PATH}/movie_stats\")\n",
    "user_profiles = spark.read.parquet(f\"{GOLD_PATH}/user_profiles\")\n",
    "\n",
    "# Zapis do PostgreSQL - tabela analityczna\n",
    "movie_stats.select(\n",
    "    \"movie_id\", \"title\", \"primary_genre\", \"total_ratings\",\n",
    "    \"avg_rating\", \"wilson_score\", \"decade\"\n",
    ").write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .jdbc(jdbc_url, \"analytics.movie_stats\", properties=properties)\n",
    "\n",
    "user_profiles.select(\n",
    "    \"user_id\", \"total_ratings\", \"avg_rating\", \"user_segment\",\n",
    "    \"positivity_rate\", \"first_activity\", \"last_activity\"\n",
    ").write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .jdbc(jdbc_url, \"analytics.user_profiles\", properties=properties)\n",
    "\n",
    "print(\"Zapisano do PostgreSQL: analytics.movie_stats, analytics.user_profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis do różnych formatów\n",
    "movie_stats_small = movie_stats.filter(col(\"total_ratings\") >= 100).limit(1000)\n",
    "\n",
    "# Parquet (kolumnowy, kompresja, szybki do analiz)\n",
    "movie_stats_small.write.mode(\"overwrite\").parquet(\"/tmp/exports/parquet\")\n",
    "\n",
    "# CSV (czytelny, kompatybilny)\n",
    "movie_stats_small.write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(\"/tmp/exports/csv\")\n",
    "\n",
    "# JSON (API-friendly)\n",
    "movie_stats_small.write.mode(\"overwrite\").json(\"/tmp/exports/json\")\n",
    "\n",
    "print(\"Eksport zakończony\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10000001",
   "metadata": {},
   "source": [
    "## Zadanie końcowe\n",
    "\n",
    "Zbuduj kompletny **ETL Pipeline** z:\n",
    "\n",
    "1. **Bronze**: Załaduj dane z PostgreSQL z metadanymi ingestii\n",
    "2. **Quality Checks**: Walidacja (nulls, ranges, referential integrity)\n",
    "3. **Silver**: Oczyszczenie, enrichment, partycjonowanie\n",
    "4. **Gold**: Stwórz 3 tabele:\n",
    "   - `daily_activity` - dzienna aktywność (oceny, unikalni użytkownicy)\n",
    "   - `genre_popularity` - ranking gatunków per dekada\n",
    "   - `user_movie_matrix` - sparse matrix user×genre z średnią oceną (dla ML)\n",
    "5. **Delta Lake**: Zapisz Gold tables jako Delta z MERGE (upsert)\n",
    "6. **PostgreSQL**: Wyeksportuj Gold do tabel analitycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import shutil\n",
    "shutil.rmtree(\"/tmp/datalake\", ignore_errors=True)\n",
    "shutil.rmtree(\"/tmp/exports\", ignore_errors=True)\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
