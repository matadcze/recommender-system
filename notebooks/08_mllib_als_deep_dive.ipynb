{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1000001",
   "metadata": {},
   "source": [
    "# 08 - MLlib ALS Deep Dive\n",
    "\n",
    "Pogłębiona nauka algorytmu ALS (Alternating Least Squares) z Spark MLlib.\n",
    "\n",
    "**Tematy:**\n",
    "- Jak działa ALS - teoria\n",
    "- Hyperparameter tuning z CrossValidator i ParamGridBuilder\n",
    "- Train / Validation / Test split\n",
    "- Strategie cold start\n",
    "- Metryki ewaluacji: RMSE, MAE, NDCG\n",
    "- Zapis i odczyt modelu (persistence)\n",
    "- Item-item similarity z wektorów latentnych\n",
    "- Implicit feedback ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1000001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/app/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /root/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /root/.ivy2.5.2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9060aa95-6045-4039-883d-07ff322ee4f5;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.7.1 in central\n",
      "\tfound org.checkerframework#checker-qual;3.41.0 in central\n",
      ":: resolution report :: resolve 96ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\torg.checkerframework#checker-qual;3.41.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.7.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9060aa95-6045-4039-883d-07ff322ee4f5\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/4ms)\n",
      "26/02/09 17:40:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "[Stage 0:====================================================>     (9 + 1) / 10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings: 20000263, Movies: 27278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"08_MLlib_ALS\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.1\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .config(\"spark.executor.memory\", \"7g\") \\\n",
    "    .config(\"spark.driver.host\", \"recommender-jupyter\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/recommender\"\n",
    "properties = {\n",
    "    \"user\": \"recommender\",\n",
    "    \"password\": \"recommender\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "ratings = spark.read.jdbc(\n",
    "    jdbc_url, \"movielens.ratings\", properties=properties,\n",
    "    column=\"user_id\", lowerBound=1, upperBound=300000, numPartitions=10\n",
    ")\n",
    "movies = spark.read.jdbc(jdbc_url, \"movielens.movies\", properties=properties)\n",
    "\n",
    "ratings.cache()\n",
    "print(f\"Ratings: {ratings.count()}, Movies: {movies.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2000001",
   "metadata": {},
   "source": [
    "## 2. Jak działa ALS - teoria\n",
    "\n",
    "ALS (Alternating Least Squares) to algorytm **collaborative filtering** oparty o **matrix factorization**.\n",
    "\n",
    "### Idea:\n",
    "Macierz ocen R (users × items) jest rzadka (sparse). ALS rozkłada ją na dwie mniejsze macierze:\n",
    "\n",
    "```\n",
    "R ≈ U × I^T\n",
    "```\n",
    "\n",
    "- **U** (users × rank) - wektor latentny użytkownika\n",
    "- **I** (items × rank) - wektor latentny filmu\n",
    "- **rank** - liczba latentnych czynników (hyperparameter)\n",
    "\n",
    "### Algorytm:\n",
    "1. Zainicjalizuj U i I losowo\n",
    "2. Zamroź I, optymalizuj U (least squares)\n",
    "3. Zamroź U, optymalizuj I (least squares)\n",
    "4. Powtórz 2-3 przez maxIter iteracji\n",
    "\n",
    "### Kluczowe parametry:\n",
    "- **rank** - wymiar wektora latentnego (10-200)\n",
    "- **maxIter** - liczba iteracji (5-20)\n",
    "- **regParam** - regularyzacja L2 (0.01-1.0)\n",
    "- **alpha** - parametr confidence (tylko implicit feedback)\n",
    "- **implicitPrefs** - czy używać implicit feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000001",
   "metadata": {},
   "source": [
    "## 3. Train / Validation / Test Split\n",
    "\n",
    "Prawidłowy podział danych:\n",
    "- **Training** (60%) - model się uczy\n",
    "- **Validation** (20%) - tuning hyperparametrów\n",
    "- **Test** (20%) - finalna ewaluacja (użyj tylko RAZ!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział danych\n",
    "(training, validation, test) = ratings.randomSplit([0.6, 0.2, 0.2], seed=42)\n",
    "\n",
    "# Cache bo będziemy wielokrotnie używać\n",
    "training.cache()\n",
    "validation.cache()\n",
    "test.cache()\n",
    "\n",
    "print(f\"Training: {training.count()}\")\n",
    "print(f\"Validation: {validation.count()}\")\n",
    "print(f\"Test: {test.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000002",
   "metadata": {},
   "source": [
    "## 4. Baseline - prosty model ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Baseline model\n",
    "als_baseline = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    rank=10,\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"movie_id\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model_baseline = als_baseline.fit(training)\n",
    "\n",
    "# Ewaluacja na validation\n",
    "predictions = model_baseline.transform(validation)\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
    ")\n",
    "evaluator_mae = RegressionEvaluator(\n",
    "    metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "print(f\"Baseline RMSE: {rmse:.4f}\")\n",
    "print(f\"Baseline MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4000001",
   "metadata": {},
   "source": [
    "## 5. Ręczny hyperparameter tuning\n",
    "\n",
    "Zanim użyjemy CrossValidator, zróbmy to ręcznie żeby zrozumieć proces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Grid search - ręczny\n",
    "ranks = [5, 10, 20]\n",
    "reg_params = [0.01, 0.1, 0.5]\n",
    "\n",
    "results = []\n",
    "\n",
    "for rank, reg in itertools.product(ranks, reg_params):\n",
    "    als = ALS(\n",
    "        maxIter=10,\n",
    "        regParam=reg,\n",
    "        rank=rank,\n",
    "        userCol=\"user_id\",\n",
    "        itemCol=\"movie_id\",\n",
    "        ratingCol=\"rating\",\n",
    "        coldStartStrategy=\"drop\",\n",
    "        seed=42\n",
    "    )\n",
    "    model = als.fit(training)\n",
    "    preds = model.transform(validation)\n",
    "    rmse = evaluator_rmse.evaluate(preds)\n",
    "    mae = evaluator_mae.evaluate(preds)\n",
    "    results.append((rank, reg, rmse, mae))\n",
    "    print(f\"rank={rank:2d}, regParam={reg:.2f} → RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Najlepszy model\n",
    "best = min(results, key=lambda x: x[2])\n",
    "print(f\"\\nNajlepszy: rank={best[0]}, regParam={best[1]}, RMSE={best[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000001",
   "metadata": {},
   "source": [
    "## 6. CrossValidator - automatyczny hyperparameter tuning\n",
    "\n",
    "CrossValidator automatycznie:\n",
    "1. Tworzy kombinacje hyperparametrów (ParamGrid)\n",
    "2. Dzieli dane na K foldów\n",
    "3. Trenuje model na K-1 foldach, ewaluuje na 1 foldzie\n",
    "4. Powtarza K razy\n",
    "5. Uśrednia metryki i wybiera najlepszą kombinację"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"movie_id\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# ParamGrid - siatka hyperparametrów do przeszukania\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20, 50]) \\\n",
    "    .addGrid(als.maxIter, [10, 15]) \\\n",
    "    .addGrid(als.regParam, [0.01, 0.1, 0.3]) \\\n",
    "    .build()\n",
    "\n",
    "print(f\"Liczba kombinacji do przetestowania: {len(param_grid)}\")\n",
    "\n",
    "# CrossValidator\n",
    "cv = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator_rmse,\n",
    "    numFolds=3,  # 3-fold CV\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Uwaga: to jest BARDZO kosztowne obliczeniowo!\n",
    "# 18 kombinacji × 3 foldy = 54 modele do wytrenowania\n",
    "# Na dużych danych może trwać godzinami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trenuj CrossValidator (to zajmie chwilę!)\n",
    "# Użyj mniejszej próbki jeśli trwa zbyt długo\n",
    "training_sample = training.sample(0.1, seed=42).cache()\n",
    "print(f\"Training sample: {training_sample.count()} rows\")\n",
    "\n",
    "cv_model = cv.fit(training_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyniki Cross Validation\n",
    "print(\"Średnie RMSE per kombinacja:\")\n",
    "for params, metric in zip(param_grid, cv_model.avgMetrics):\n",
    "    rank = params[als.rank]\n",
    "    maxIter = params[als.maxIter]\n",
    "    regParam = params[als.regParam]\n",
    "    print(f\"  rank={rank:2d}, maxIter={maxIter:2d}, regParam={regParam:.2f} → RMSE={metric:.4f}\")\n",
    "\n",
    "# Najlepszy model\n",
    "best_model = cv_model.bestModel\n",
    "print(f\"\\nNajlepszy model:\")\n",
    "print(f\"  rank: {best_model.rank}\")\n",
    "print(f\"  Validation RMSE: {min(cv_model.avgMetrics):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000002",
   "metadata": {},
   "source": [
    "### TrainValidationSplit - szybsza alternatywa\n",
    "\n",
    "Zamiast K-fold CV, trenuje na jednym splicie. Szybszy ale mniej dokładny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator_rmse,\n",
    "    trainRatio=0.8,  # 80% train, 20% validation\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Szybszy niż CrossValidator!\n",
    "tvs_model = tvs.fit(training_sample)\n",
    "\n",
    "best_tvs_model = tvs_model.bestModel\n",
    "print(f\"Najlepszy model (TVS): rank={best_tvs_model.rank}\")\n",
    "print(f\"Best RMSE: {min(tvs_model.validationMetrics):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000003",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "Wytrenuj najlepszy model na pełnych danych treningowych z najlepszymi hyperparametrami znalezionymi powyżej.\n",
    "Ewaluuj na zbiorze walidacyjnym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6000001",
   "metadata": {},
   "source": [
    "## 7. Strategie Cold Start\n",
    "\n",
    "**Cold start problem** - nowy użytkownik/film bez ocen. Model nie ma informacji.\n",
    "\n",
    "ALS coldStartStrategy:\n",
    "- `\"nan\"` - zwraca NaN (domyślne)\n",
    "- `\"drop\"` - pomija wiersze z NaN w predykcji\n",
    "\n",
    "Dodatkowe strategie (do implementacji ręcznej):\n",
    "- Popularne filmy (fallback)\n",
    "- Content-based features\n",
    "- Hybrydowe podejścia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wytrenuj model na zbiorze treningowym\n",
    "als_full = ALS(\n",
    "    maxIter=10, regParam=0.1, rank=20,\n",
    "    userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"nan\",  # zostawmy NaN żeby zobaczyć problem\n",
    "    seed=42\n",
    ")\n",
    "model_full = als_full.fit(training)\n",
    "\n",
    "# Predykcja na test - mogą być NaN\n",
    "preds_nan = model_full.transform(test)\n",
    "nan_count = preds_nan.filter(col(\"prediction\").isNull() | isnan(col(\"prediction\"))).count()\n",
    "total = preds_nan.count()\n",
    "print(f\"NaN predictions: {nan_count} / {total} ({nan_count/total*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategia fallback: zastąp NaN popularnymi filmami\n",
    "global_avg = training.agg(avg(\"rating\")).collect()[0][0]\n",
    "print(f\"Globalna średnia ocena: {global_avg:.2f}\")\n",
    "\n",
    "# Zastąp NaN globalną średnią\n",
    "preds_filled = preds_nan.withColumn(\n",
    "    \"prediction_filled\",\n",
    "    when(col(\"prediction\").isNull() | isnan(col(\"prediction\")), global_avg)\n",
    "    .otherwise(col(\"prediction\"))\n",
    ")\n",
    "\n",
    "# Ewaluuj z fallback\n",
    "evaluator_filled = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction_filled\"\n",
    ")\n",
    "rmse_filled = evaluator_filled.evaluate(preds_filled)\n",
    "print(f\"RMSE z fallback: {rmse_filled:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lepszy fallback: średnia ocena per film (zamiast globalnej)\n",
    "movie_avg = training.groupBy(\"movie_id\").agg(\n",
    "    avg(\"rating\").alias(\"movie_avg_rating\")\n",
    ")\n",
    "\n",
    "preds_smart = preds_nan.join(movie_avg, \"movie_id\", \"left\") \\\n",
    "    .withColumn(\n",
    "        \"prediction_smart\",\n",
    "        when(col(\"prediction\").isNull() | isnan(col(\"prediction\")),\n",
    "             coalesce(col(\"movie_avg_rating\"), lit(global_avg)))\n",
    "        .otherwise(col(\"prediction\"))\n",
    "    )\n",
    "\n",
    "evaluator_smart = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction_smart\"\n",
    ")\n",
    "rmse_smart = evaluator_smart.evaluate(preds_smart)\n",
    "print(f\"RMSE z smart fallback: {rmse_smart:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7000001",
   "metadata": {},
   "source": [
    "## 8. Metryki ewaluacji\n",
    "\n",
    "### Rating prediction metrics:\n",
    "- **RMSE** - Root Mean Squared Error (karze duże błędy)\n",
    "- **MAE** - Mean Absolute Error (bardziej odporny na outliers)\n",
    "\n",
    "### Ranking metrics (ważniejsze dla rekomendacji!):\n",
    "- **Precision@K** - ile z top K rekomendacji jest trafnych\n",
    "- **Recall@K** - ile trafnych filmów jest w top K\n",
    "- **NDCG@K** - Normalized Discounted Cumulative Gain (uwzględnia pozycję)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model z coldStartStrategy=\"drop\" do metryk rankingowych\n",
    "als_ranking = ALS(\n",
    "    maxIter=10, regParam=0.1, rank=20,\n",
    "    userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\", seed=42\n",
    ")\n",
    "model_ranking = als_ranking.fit(training)\n",
    "\n",
    "# RMSE i MAE\n",
    "preds = model_ranking.transform(test)\n",
    "print(f\"RMSE: {evaluator_rmse.evaluate(preds):.4f}\")\n",
    "print(f\"MAE:  {evaluator_mae.evaluate(preds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision@K i Recall@K - ręczna implementacja\n",
    "K = 10\n",
    "THRESHOLD = 4.0  # filmy z oceną >= 4.0 uznajemy za \"trafne\"\n",
    "\n",
    "# Ground truth: filmy które użytkownik ocenił wysoko w zbiorze testowym\n",
    "relevant_items = test.filter(col(\"rating\") >= THRESHOLD) \\\n",
    "    .groupBy(\"user_id\") \\\n",
    "    .agg(collect_set(\"movie_id\").alias(\"relevant_movies\"))\n",
    "\n",
    "# Top K rekomendacji z modelu\n",
    "user_recs = model_ranking.recommendForAllUsers(K)\n",
    "\n",
    "# Rozpakuj rekomendacje\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "user_recs_flat = user_recs.select(\n",
    "    col(\"user_id\"),\n",
    "    expr(\"transform(recommendations, x -> x.movie_id)\").alias(\"recommended_movies\")\n",
    ")\n",
    "\n",
    "user_recs_flat.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join i policz Precision@K, Recall@K\n",
    "metrics = user_recs_flat.join(relevant_items, \"user_id\") \\\n",
    "    .withColumn(\n",
    "        \"hits\",\n",
    "        size(array_intersect(col(\"recommended_movies\"), col(\"relevant_movies\")))\n",
    "    ) \\\n",
    "    .withColumn(\"precision_at_k\", col(\"hits\") / K) \\\n",
    "    .withColumn(\"recall_at_k\", col(\"hits\") / size(col(\"relevant_movies\")))\n",
    "\n",
    "avg_metrics = metrics.agg(\n",
    "    round(avg(\"precision_at_k\"), 4).alias(\"avg_precision_at_k\"),\n",
    "    round(avg(\"recall_at_k\"), 4).alias(\"avg_recall_at_k\")\n",
    ")\n",
    "\n",
    "avg_metrics.show()\n",
    "\n",
    "# Rozkład metryk\n",
    "metrics.select(\"precision_at_k\", \"recall_at_k\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDCG@K - Normalized Discounted Cumulative Gain\n",
    "# Uwzględnia POZYCJĘ trafienia - trafienie na pozycji 1 jest cenniejsze niż na pozycji 10\n",
    "\n",
    "from pyspark.sql.types import FloatType, ArrayType\n",
    "import numpy as np\n",
    "\n",
    "@udf(FloatType())\n",
    "def ndcg_at_k(recommended, relevant, k=10):\n",
    "    \"\"\"Calculate NDCG@K.\"\"\"\n",
    "    if not recommended or not relevant:\n",
    "        return 0.0\n",
    "    \n",
    "    relevant_set = set(relevant)\n",
    "    \n",
    "    # DCG\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended[:k]):\n",
    "        if item in relevant_set:\n",
    "            dcg += 1.0 / np.log2(i + 2)  # +2 bo log2(1)=0\n",
    "    \n",
    "    # Ideal DCG (wszystkie trafienia na początku)\n",
    "    ideal_hits = min(len(relevant_set), k)\n",
    "    idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal_hits))\n",
    "    \n",
    "    return float(dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "# Policz NDCG@10\n",
    "ndcg_result = user_recs_flat.join(relevant_items, \"user_id\") \\\n",
    "    .withColumn(\"ndcg\", ndcg_at_k(col(\"recommended_movies\"), col(\"relevant_movies\")))\n",
    "\n",
    "avg_ndcg = ndcg_result.agg(round(avg(\"ndcg\"), 4).alias(\"avg_ndcg_at_10\")).collect()[0][0]\n",
    "print(f\"Average NDCG@10: {avg_ndcg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7000002",
   "metadata": {},
   "source": [
    "### Zadanie 2\n",
    "Porównaj metryki rankingowe (Precision@K, NDCG@K) dla modeli z rank=10 i rank=50.\n",
    "Czy większy rank zawsze jest lepszy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8000001",
   "metadata": {},
   "source": [
    "## 9. Model Persistence - zapis i odczyt modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisz model\n",
    "model_path = \"/tmp/als_model\"\n",
    "model_ranking.write().overwrite().save(model_path)\n",
    "print(f\"Model zapisany do: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odczytaj model\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "\n",
    "loaded_model = ALSModel.load(model_path)\n",
    "print(f\"Załadowany model: rank={loaded_model.rank}\")\n",
    "\n",
    "# Weryfikacja - te same predykcje?\n",
    "preds_loaded = loaded_model.transform(test)\n",
    "rmse_loaded = evaluator_rmse.evaluate(preds_loaded)\n",
    "print(f\"RMSE załadowanego modelu: {rmse_loaded:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisz cały pipeline (CrossValidator model)\n",
    "# cv_model.write().overwrite().save(\"/tmp/als_cv_model\")\n",
    "\n",
    "# Zapisz też metadane modelu\n",
    "model_metadata = spark.createDataFrame([\n",
    "    (\"rank\", str(model_ranking.rank)),\n",
    "    (\"rmse\", str(rmse_loaded)),\n",
    "    (\"training_size\", str(training.count())),\n",
    "    (\"timestamp\", str(current_timestamp()))\n",
    "], [\"key\", \"value\"])\n",
    "\n",
    "model_metadata.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9000001",
   "metadata": {},
   "source": [
    "## 10. Item-Item Similarity z wektorów latentnych\n",
    "\n",
    "Wektory latentne z ALS mogą być użyte do znalezienia podobnych filmów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobierz item factors\n",
    "item_factors = model_ranking.itemFactors\n",
    "user_factors = model_ranking.userFactors\n",
    "\n",
    "print(f\"Item factors: {item_factors.count()} items × rank={model_ranking.rank}\")\n",
    "print(f\"User factors: {user_factors.count()} users × rank={model_ranking.rank}\")\n",
    "\n",
    "item_factors.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity - znajdź filmy podobne do danego\n",
    "import numpy as np\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "def find_similar_movies(target_movie_id, n=10):\n",
    "    \"\"\"Znajdź n filmów najbardziej podobnych do target_movie_id.\"\"\"\n",
    "    \n",
    "    # Pobierz wektor docelowego filmu\n",
    "    target_vector = item_factors.filter(col(\"id\") == target_movie_id) \\\n",
    "        .select(\"features\").collect()[0][0]\n",
    "    target_np = np.array(target_vector)\n",
    "    \n",
    "    # UDF do cosine similarity\n",
    "    @udf(DoubleType())\n",
    "    def cosine_sim(features):\n",
    "        v = np.array(features)\n",
    "        return float(np.dot(target_np, v) / (np.linalg.norm(target_np) * np.linalg.norm(v)))\n",
    "    \n",
    "    # Policz similarity dla wszystkich filmów\n",
    "    similar = item_factors \\\n",
    "        .withColumn(\"similarity\", cosine_sim(col(\"features\"))) \\\n",
    "        .filter(col(\"id\") != target_movie_id) \\\n",
    "        .orderBy(desc(\"similarity\")) \\\n",
    "        .limit(n) \\\n",
    "        .withColumnRenamed(\"id\", \"movie_id\") \\\n",
    "        .join(movies, \"movie_id\") \\\n",
    "        .select(\"movie_id\", \"title\", \"genres\", \"similarity\")\n",
    "    \n",
    "    return similar\n",
    "\n",
    "# Filmy podobne do Toy Story (1995) - movie_id=1\n",
    "print(\"Filmy podobne do Toy Story (1995):\")\n",
    "find_similar_movies(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filmy podobne do The Matrix (1999) - movie_id=2571\n",
    "print(\"Filmy podobne do The Matrix (1999):\")\n",
    "find_similar_movies(2571).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filmy podobne do The Shawshank Redemption (1994) - movie_id=318\n",
    "print(\"Filmy podobne do The Shawshank Redemption (1994):\")\n",
    "find_similar_movies(318).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10000001",
   "metadata": {},
   "source": [
    "## 11. Implicit Feedback ALS\n",
    "\n",
    "W wielu systemach nie mamy explicit ocen - mamy tylko sygnały implicit:\n",
    "- Ile razy użytkownik obejrzał film\n",
    "- Czy kliknął\n",
    "- Czas spędzony na stronie\n",
    "\n",
    "ALS z `implicitPrefs=True` interpretuje dane jako **confidence** a nie ocenę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symuluj implicit feedback - zamieniamy oceny na binarne \"interakcje\"\n",
    "# rating >= 4.0 → 1 (user liked), reszta → 0\n",
    "implicit_data = ratings.withColumn(\n",
    "    \"interaction\",\n",
    "    when(col(\"rating\") >= 4.0, 1.0).otherwise(0.0)\n",
    ")\n",
    "\n",
    "implicit_data.groupBy(\"interaction\").count().show()\n",
    "\n",
    "(train_impl, test_impl) = implicit_data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS z implicit feedback\n",
    "als_implicit = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    rank=20,\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"movie_id\",\n",
    "    ratingCol=\"interaction\",\n",
    "    implicitPrefs=True,  # implicit mode!\n",
    "    alpha=40.0,  # confidence scaling factor\n",
    "    coldStartStrategy=\"drop\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model_implicit = als_implicit.fit(train_impl)\n",
    "\n",
    "# Rekomendacje - wartości w (0, 1) zamiast (0.5, 5.0)\n",
    "user_42_recs = model_implicit.recommendForUserSubset(\n",
    "    spark.createDataFrame([(42,)], [\"user_id\"]), 10\n",
    ")\n",
    "\n",
    "user_42_recs.select(\"user_id\", explode(\"recommendations\").alias(\"rec\")) \\\n",
    "    .select(\"user_id\", \"rec.movie_id\", \"rec.rating\") \\\n",
    "    .join(movies, \"movie_id\") \\\n",
    "    .select(\"title\", \"rating\") \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11000001",
   "metadata": {},
   "source": [
    "## Zadanie końcowe\n",
    "\n",
    "Zbuduj pełny pipeline rekomendacji:\n",
    "\n",
    "1. Podziel dane na train/validation/test (60/20/20)\n",
    "2. Użyj TrainValidationSplit z ParamGrid (rank: [10, 30, 50], regParam: [0.05, 0.1, 0.2])\n",
    "3. Wytrenuj najlepszy model na pełnym zbiorze treningowym\n",
    "4. Ewaluuj na teście: RMSE, MAE, Precision@10, NDCG@10\n",
    "5. Dla wybranego użytkownika pokaż:\n",
    "   - Jego 10 najwyżej ocenionych filmów (ground truth)\n",
    "   - 10 rekomendacji modelu\n",
    "   - Czy rekomendacje mają sens?\n",
    "6. Zapisz model do pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.unpersist()\n",
    "training.unpersist()\n",
    "validation.unpersist()\n",
    "test.unpersist()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
