{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 04 - Spark DataFrame Operations\n",
    "\n",
    "Nauka podstawowych operacji na DataFrame w Apache Spark na danych MovieLens.\n",
    "\n",
    "**Tematy:**\n",
    "- Tworzenie SparkSession i ładowanie danych\n",
    "- Inspekcja schematu (printSchema, dtypes, describe)\n",
    "- select, selectExpr\n",
    "- filter / where\n",
    "- withColumn, drop, withColumnRenamed\n",
    "- sort / orderBy\n",
    "- join (inner, left, right, cross)\n",
    "- union, distinct, dropDuplicates\n",
    "- limit, sample, take"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "## 1. SparkSession + ładowanie danych z PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"04_DataFrame_Operations\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.1\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .config(\"spark.executor.memory\", \"7g\") \\\n",
    "    .config(\"spark.driver.host\", \"recommender-jupyter\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/recommender\"\n",
    "properties = {\n",
    "    \"user\": \"recommender\",\n",
    "    \"password\": \"recommender\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.jdbc(\n",
    "    jdbc_url, \"movielens.ratings\", properties=properties,\n",
    "    column=\"user_id\", lowerBound=1, upperBound=300000, numPartitions=10\n",
    ")\n",
    "movies = spark.read.jdbc(jdbc_url, \"movielens.movies\", properties=properties)\n",
    "\n",
    "print(f\"Ratings: {ratings.count()} rows\")\n",
    "print(f\"Movies: {movies.count()} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2000001",
   "metadata": {},
   "source": [
    "## 2. Inspekcja schematu\n",
    "\n",
    "Zanim zaczniesz pracę z DataFrame, zawsze warto sprawdzić jego strukturę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printSchema() - pełna struktura z typami danych\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes - lista krotek (nazwa, typ)\n",
    "print(ratings.dtypes)\n",
    "\n",
    "# columns - lista nazw kolumn\n",
    "print(ratings.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe() - statystyki dla kolumn numerycznych\n",
    "ratings.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary() - rozszerzone statystyki (25%, 50%, 75% percentyle)\n",
    "ratings.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000001",
   "metadata": {},
   "source": [
    "## 3. select i selectExpr\n",
    "\n",
    "`select` - wybiera kolumny (jak SELECT w SQL)  \n",
    "`selectExpr` - pozwala używać wyrażeń SQL jako stringów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, upper, lower, length\n",
    "\n",
    "# select - po nazwie kolumny\n",
    "ratings.select(\"user_id\", \"movie_id\", \"rating\").show(5)\n",
    "\n",
    "# select - z użyciem col()\n",
    "ratings.select(col(\"user_id\"), col(\"rating\") * 2).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectExpr - wyrażenia SQL jako stringi\n",
    "ratings.selectExpr(\n",
    "    \"user_id\",\n",
    "    \"movie_id\",\n",
    "    \"rating\",\n",
    "    \"rating * 2 as double_rating\",\n",
    "    \"CASE WHEN rating >= 4.0 THEN 'high' ELSE 'low' END as rating_category\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000002",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "Wybierz z tabeli `movies` kolumny `title` i `genres`, dodaj kolumnę `title_length` z długością tytułu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4000001",
   "metadata": {},
   "source": [
    "## 4. filter / where\n",
    "\n",
    "Filtrowanie wierszy - `filter` i `where` działają identycznie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrowanie po wartości\n",
    "high_ratings = ratings.filter(col(\"rating\") >= 4.5)\n",
    "print(f\"Oceny >= 4.5: {high_ratings.count()}\")\n",
    "high_ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrowanie z użyciem stringa SQL\n",
    "ratings.where(\"rating >= 4.5 AND user_id < 100\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Łączenie warunków: & (AND), | (OR), ~ (NOT)\n",
    "ratings.filter(\n",
    "    (col(\"rating\") >= 4.0) & (col(\"user_id\").between(1, 50))\n",
    ").show(5)\n",
    "\n",
    "# isNull / isNotNull\n",
    "movies.filter(col(\"genres\").isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isin - filtrowanie po liście wartości\n",
    "selected_users = [1, 42, 100, 500]\n",
    "ratings.filter(col(\"user_id\").isin(selected_users)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like / rlike (regex) na stringach\n",
    "movies.filter(col(\"title\").like(\"%Toy Story%\")).show()\n",
    "\n",
    "# Filmy z roku 2015 (regex)\n",
    "movies.filter(col(\"title\").rlike(r\"\\(2015\\)\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4000002",
   "metadata": {},
   "source": [
    "### Zadanie 2\n",
    "Znajdź wszystkie filmy, które mają gatunek \"Comedy\" I zostały wydane po roku 2000 (użyj rlike na tytule)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000001",
   "metadata": {},
   "source": [
    "## 5. withColumn, drop, withColumnRenamed\n",
    "\n",
    "Modyfikacja kolumn - Spark DataFrame jest niemutowalny, więc każda operacja zwraca nowy DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, regexp_extract, split, size, year, to_timestamp\n",
    "\n",
    "# withColumn - dodaj nową kolumnę lub nadpisz istniejącą\n",
    "movies_enriched = movies \\\n",
    "    .withColumn(\"year\", regexp_extract(col(\"title\"), r\"\\((\\d{4})\\)\", 1).cast(\"int\")) \\\n",
    "    .withColumn(\"genre_count\", size(split(col(\"genres\"), \"\\\\|\"))) \\\n",
    "    .withColumn(\"is_comedy\", col(\"genres\").contains(\"Comedy\"))\n",
    "\n",
    "movies_enriched.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# withColumnRenamed\n",
    "movies_renamed = movies.withColumnRenamed(\"movie_id\", \"id\") \\\n",
    "                       .withColumnRenamed(\"title\", \"movie_title\")\n",
    "movies_renamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop - usuń kolumnę\n",
    "ratings_slim = ratings.drop(\"rating_timestamp\")\n",
    "ratings_slim.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when / otherwise - odpowiednik CASE WHEN\n",
    "ratings_labeled = ratings.withColumn(\n",
    "    \"rating_label\",\n",
    "    when(col(\"rating\") >= 4.0, \"positive\")\n",
    "    .when(col(\"rating\") >= 3.0, \"neutral\")\n",
    "    .otherwise(\"negative\")\n",
    ")\n",
    "ratings_labeled.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000002",
   "metadata": {},
   "source": [
    "### Zadanie 3\n",
    "Dodaj do `ratings` kolumnę `decade` - dekadę, w której film został oceniony (na podstawie `rating_timestamp`).\n",
    "Np. 2005 → 2000, 2013 → 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6000001",
   "metadata": {},
   "source": [
    "## 6. sort / orderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, asc\n",
    "\n",
    "# Sortowanie rosnąco (domyślnie)\n",
    "movies.orderBy(\"title\").show(5)\n",
    "\n",
    "# Sortowanie malejąco\n",
    "movies.orderBy(desc(\"movie_id\")).show(5)\n",
    "\n",
    "# Sortowanie po wielu kolumnach\n",
    "ratings.orderBy(asc(\"user_id\"), desc(\"rating\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7000001",
   "metadata": {},
   "source": [
    "## 7. join\n",
    "\n",
    "Łączenie DataFrames - kluczowa operacja w Spark.\n",
    "\n",
    "Typy joinów:\n",
    "- `inner` (domyślny) - tylko dopasowane wiersze\n",
    "- `left` / `left_outer` - wszystko z lewej + dopasowane z prawej\n",
    "- `right` / `right_outer` - wszystko z prawej + dopasowane z lewej\n",
    "- `full` / `full_outer` / `outer` - wszystko z obu stron\n",
    "- `cross` - iloczyn kartezjański\n",
    "- `left_semi` - wiersze z lewej, które mają dopasowanie (bez kolumn z prawej)\n",
    "- `left_anti` - wiersze z lewej, które NIE mają dopasowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join - oceny z tytułami filmów\n",
    "ratings_with_titles = ratings.join(movies, \"movie_id\")\n",
    "ratings_with_titles.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_anti - filmy BEZ żadnej oceny\n",
    "movies_without_ratings = movies.join(ratings, \"movie_id\", \"left_anti\")\n",
    "print(f\"Filmy bez ocen: {movies_without_ratings.count()}\")\n",
    "movies_without_ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_semi - filmy które MAJĄ przynajmniej jedną ocenę (bez kolumn z ratings)\n",
    "movies_with_ratings = movies.join(ratings, \"movie_id\", \"left_semi\")\n",
    "print(f\"Filmy z ocenami: {movies_with_ratings.count()}\")\n",
    "movies_with_ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join z różnymi nazwami kolumn\n",
    "movies_renamed = movies.withColumnRenamed(\"movie_id\", \"id\")\n",
    "ratings.join(movies_renamed, ratings.movie_id == movies_renamed.id, \"inner\") \\\n",
    "    .drop(\"id\") \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7000002",
   "metadata": {},
   "source": [
    "### Zadanie 4\n",
    "Znajdź 10 filmów z największą liczbą ocen. Użyj join z movies, żeby pokazać tytuły."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8000001",
   "metadata": {},
   "source": [
    "## 8. union, distinct, dropDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# union - łączenie dwóch DataFrames (muszą mieć ten sam schemat)\n",
    "comedies = movies.filter(col(\"genres\").contains(\"Comedy\"))\n",
    "dramas = movies.filter(col(\"genres\").contains(\"Drama\"))\n",
    "\n",
    "comedies_or_dramas = comedies.union(dramas)\n",
    "print(f\"Komedie: {comedies.count()}\")\n",
    "print(f\"Dramaty: {dramas.count()}\")\n",
    "print(f\"Union (z duplikatami): {comedies_or_dramas.count()}\")\n",
    "print(f\"Union (bez duplikatów): {comedies_or_dramas.distinct().count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropDuplicates - usuwanie duplikatów po wybranych kolumnach\n",
    "# Np. jeden wiersz na użytkownika (pierwsza ocena)\n",
    "unique_users = ratings.dropDuplicates([\"user_id\"])\n",
    "print(f\"Unikalni użytkownicy: {unique_users.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9000001",
   "metadata": {},
   "source": [
    "## 9. limit, sample, take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit - zwraca nowy DataFrame z N pierwszych wierszy\n",
    "ratings.limit(5).show()\n",
    "\n",
    "# sample - losowa próbka (fraction = procent danych)\n",
    "sample_ratings = ratings.sample(fraction=0.001, seed=42)\n",
    "print(f\"Próbka 0.1%: {sample_ratings.count()} wierszy\")\n",
    "\n",
    "# take - zwraca listę Row obiektów (do drivera!)\n",
    "rows = ratings.take(3)\n",
    "for r in rows:\n",
    "    print(f\"User {r.user_id} rated movie {r.movie_id}: {r.rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10000001",
   "metadata": {},
   "source": [
    "## 10. cache / persist\n",
    "\n",
    "Jeśli DataFrame jest używany wielokrotnie, warto go zcachować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel\n",
    "\n",
    "# cache() = persist(StorageLevel.MEMORY_AND_DISK)\n",
    "ratings.cache()\n",
    "\n",
    "# Pierwsza akcja - wczytuje dane do pamięci\n",
    "ratings.count()\n",
    "\n",
    "# Kolejne akcje będą szybsze\n",
    "ratings.filter(col(\"rating\") == 5.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdź w Spark UI -> Storage tab\n",
    "# Zwolnij cache\n",
    "ratings.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11000001",
   "metadata": {},
   "source": [
    "## Zadanie końcowe\n",
    "\n",
    "Stwórz DataFrame `user_profiles` zawierający dla każdego użytkownika:\n",
    "- `user_id`\n",
    "- `total_ratings` - liczba ocen\n",
    "- `avg_rating` - średnia ocena\n",
    "- `favorite_genre` - najczęściej oceniany gatunek (wymaga joina z movies i rozbicia genres)\n",
    "\n",
    "Posortuj malejąco po `total_ratings` i pokaż top 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
