{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1000001",
   "metadata": {},
   "source": [
    "# 14 - Projekty Integracyjne\n",
    "\n",
    "Łączenie Sparka z innymi komponentami systemu rekomendacji.\n",
    "\n",
    "**Tematy:**\n",
    "- Feature Store - prekomputuj features w Spark, serwuj z PostgreSQL\n",
    "- Model Export - eksport faktorów ALS do formatu serwowalnego\n",
    "- Batch Scoring Pipeline - generowanie rekomendacji w batchu\n",
    "- A/B Testing Framework - porównanie modeli\n",
    "- Lambda Architecture - batch + speed layer\n",
    "- End-to-end pipeline: train → export → serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"14_Integration\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.1\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .config(\"spark.executor.memory\", \"7g\") \\\n",
    "    .config(\"spark.driver.host\", \"recommender-jupyter\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/recommender\"\n",
    "properties = {\n",
    "    \"user\": \"recommender\",\n",
    "    \"password\": \"recommender\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "ratings = spark.read.jdbc(\n",
    "    jdbc_url, \"movielens.ratings\", properties=properties,\n",
    "    column=\"user_id\", lowerBound=1, upperBound=300000, numPartitions=10\n",
    ")\n",
    "movies = spark.read.jdbc(jdbc_url, \"movielens.movies\", properties=properties)\n",
    "\n",
    "ratings.cache()\n",
    "movies.cache()\n",
    "print(f\"Ratings: {ratings.count()}, Movies: {movies.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2000001",
   "metadata": {},
   "source": [
    "## 2. Feature Store\n",
    "\n",
    "Feature Store = prekomputowane features gotowe do użycia przez modele ML i API.\n",
    "\n",
    "**Pipeline:**\n",
    "```\n",
    "Spark (batch)  →  PostgreSQL (feature store)  →  FastAPI (serving)\n",
    "                    ↑ odświeżanie nocne            ↑ odczyt <10ms\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === USER FEATURES ===\n",
    "\n",
    "user_features = ratings.groupBy(\"user_id\").agg(\n",
    "    count(\"*\").alias(\"total_ratings\"),\n",
    "    round(avg(\"rating\"), 4).alias(\"avg_rating\"),\n",
    "    round(stddev(\"rating\"), 4).alias(\"std_rating\"),\n",
    "    sum(when(col(\"rating\") >= 4.0, 1).otherwise(0)).alias(\"positive_count\"),\n",
    "    sum(when(col(\"rating\") <= 2.0, 1).otherwise(0)).alias(\"negative_count\"),\n",
    "    countDistinct(\"movie_id\").alias(\"unique_movies\"),\n",
    "    min(\"rating_timestamp\").alias(\"first_rating_at\"),\n",
    "    max(\"rating_timestamp\").alias(\"last_rating_at\")\n",
    ")\n",
    "\n",
    "# Dodaj derived features\n",
    "user_features = user_features \\\n",
    "    .withColumn(\"positivity_ratio\", round(col(\"positive_count\") / col(\"total_ratings\"), 4)) \\\n",
    "    .withColumn(\"activity_span_days\",\n",
    "        datediff(col(\"last_rating_at\"), col(\"first_rating_at\"))\n",
    "    ) \\\n",
    "    .withColumn(\"ratings_per_day\",\n",
    "        when(col(\"activity_span_days\") > 0,\n",
    "             round(col(\"total_ratings\") / col(\"activity_span_days\"), 4))\n",
    "        .otherwise(col(\"total_ratings\").cast(\"double\"))\n",
    "    ) \\\n",
    "    .withColumn(\"user_segment\",\n",
    "        when(col(\"total_ratings\") >= 1000, \"power\")\n",
    "        .when(col(\"total_ratings\") >= 100, \"active\")\n",
    "        .when(col(\"total_ratings\") >= 20, \"casual\")\n",
    "        .otherwise(\"new\")\n",
    "    ) \\\n",
    "    .withColumn(\"_computed_at\", current_timestamp())\n",
    "\n",
    "print(f\"User features: {user_features.count()} users\")\n",
    "user_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MOVIE FEATURES ===\n",
    "\n",
    "movie_features = ratings.groupBy(\"movie_id\").agg(\n",
    "    count(\"*\").alias(\"total_ratings\"),\n",
    "    round(avg(\"rating\"), 4).alias(\"avg_rating\"),\n",
    "    round(stddev(\"rating\"), 4).alias(\"std_rating\"),\n",
    "    countDistinct(\"user_id\").alias(\"unique_raters\"),\n",
    "    round(avg(when(col(\"rating\") >= 4.0, 1).otherwise(0)), 4).alias(\"positive_rate\"),\n",
    "    min(\"rating_timestamp\").alias(\"first_rated_at\"),\n",
    "    max(\"rating_timestamp\").alias(\"last_rated_at\")\n",
    ")\n",
    "\n",
    "# Join z movie metadata\n",
    "movie_features = movie_features.join(movies, \"movie_id\") \\\n",
    "    .withColumn(\"year\", regexp_extract(col(\"title\"), r\"\\((\\d{4})\\)\", 1).cast(\"int\")) \\\n",
    "    .withColumn(\"primary_genre\", element_at(split(col(\"genres\"), \"\\\\|\"), 1)) \\\n",
    "    .withColumn(\"num_genres\", size(split(col(\"genres\"), \"\\\\|\"))) \\\n",
    "    .withColumn(\"_computed_at\", current_timestamp())\n",
    "\n",
    "print(f\"Movie features: {movie_features.count()} movies\")\n",
    "movie_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === USER-GENRE PREFERENCE FEATURES ===\n",
    "# Macierz: user × genre → średnia ocena\n",
    "\n",
    "user_genre_prefs = ratings.join(\n",
    "    movies.select(\"movie_id\", \"genres\"), \"movie_id\"\n",
    ").withColumn(\n",
    "    \"genre\", explode(split(col(\"genres\"), \"\\\\|\"))\n",
    ").groupBy(\"user_id\", \"genre\").agg(\n",
    "    count(\"*\").alias(\"genre_count\"),\n",
    "    round(avg(\"rating\"), 4).alias(\"genre_avg_rating\")\n",
    ")\n",
    "\n",
    "# Pivot do szerokiej tabeli (kolumna per gatunek)\n",
    "top_genres = [\"Drama\", \"Comedy\", \"Action\", \"Thriller\", \"Romance\",\n",
    "              \"Adventure\", \"Sci-Fi\", \"Crime\", \"Horror\", \"Animation\"]\n",
    "\n",
    "user_genre_wide = user_genre_prefs \\\n",
    "    .filter(col(\"genre\").isin(top_genres)) \\\n",
    "    .groupBy(\"user_id\") \\\n",
    "    .pivot(\"genre\", top_genres) \\\n",
    "    .agg(first(\"genre_avg_rating\")) \\\n",
    "    .fillna(0.0)\n",
    "\n",
    "# Renamed columns\n",
    "for g in top_genres:\n",
    "    user_genre_wide = user_genre_wide.withColumnRenamed(g, f\"pref_{g.lower().replace('-', '_')}\")\n",
    "\n",
    "user_genre_wide.withColumn(\"_computed_at\", current_timestamp())\n",
    "\n",
    "print(f\"User-genre preferences: {user_genre_wide.count()} users × {len(top_genres)} genres\")\n",
    "user_genre_wide.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXPORT DO POSTGRESQL ===\n",
    "\n",
    "# Zapisz features do PostgreSQL (feature store)\n",
    "user_features.write.mode(\"overwrite\") \\\n",
    "    .jdbc(jdbc_url, \"features.user_features\", properties=properties)\n",
    "\n",
    "movie_features.select(\n",
    "    \"movie_id\", \"title\", \"genres\", \"primary_genre\", \"year\", \"num_genres\",\n",
    "    \"total_ratings\", \"avg_rating\", \"std_rating\", \"unique_raters\",\n",
    "    \"positive_rate\", \"_computed_at\"\n",
    ").write.mode(\"overwrite\") \\\n",
    "    .jdbc(jdbc_url, \"features.movie_features\", properties=properties)\n",
    "\n",
    "user_genre_wide.write.mode(\"overwrite\") \\\n",
    "    .jdbc(jdbc_url, \"features.user_genre_preferences\", properties=properties)\n",
    "\n",
    "print(\"Feature store exported to PostgreSQL (schema: features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000001",
   "metadata": {},
   "source": [
    "## 3. Model Export - faktory ALS do serwowania\n",
    "\n",
    "Zamiast serwować z Spark (wolne), eksportujemy wektory latentne do PostgreSQL.\n",
    "\n",
    "**Serving:**\n",
    "1. User request → FastAPI\n",
    "2. FastAPI ładuje user_factor z PostgreSQL\n",
    "3. Mnożenie user_factor × item_factors = scores\n",
    "4. Top N filmów → response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trenuj ALS\n",
    "als = ALS(\n",
    "    maxIter=10, regParam=0.1, rank=20,\n",
    "    userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\", seed=42\n",
    ")\n",
    "model = als.fit(ratings)\n",
    "\n",
    "# Eksportuj faktory\n",
    "user_factors = model.userFactors \\\n",
    "    .withColumnRenamed(\"id\", \"user_id\") \\\n",
    "    .withColumn(\"features_json\",\n",
    "        to_json(col(\"features\").cast(ArrayType(DoubleType()))))\n",
    "\n",
    "item_factors = model.itemFactors \\\n",
    "    .withColumnRenamed(\"id\", \"movie_id\") \\\n",
    "    .withColumn(\"features_json\",\n",
    "        to_json(col(\"features\").cast(ArrayType(DoubleType()))))\n",
    "\n",
    "print(f\"User factors: {user_factors.count()} users × rank={model.rank}\")\n",
    "print(f\"Item factors: {item_factors.count()} items × rank={model.rank}\")\n",
    "\n",
    "user_factors.select(\"user_id\", \"features_json\").show(3, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksport do PostgreSQL\n",
    "user_factors.select(\"user_id\", \"features_json\") \\\n",
    "    .write.mode(\"overwrite\") \\\n",
    "    .jdbc(jdbc_url, \"models.user_factors\", properties=properties)\n",
    "\n",
    "item_factors.select(\"movie_id\", \"features_json\") \\\n",
    "    .write.mode(\"overwrite\") \\\n",
    "    .jdbc(jdbc_url, \"models.item_factors\", properties=properties)\n",
    "\n",
    "# Metadane modelu\n",
    "model_metadata = spark.createDataFrame([\n",
    "    (\"als_v1\", model.rank, 10, 0.1, float(ratings.count()), str(current_timestamp()))\n",
    "], [\"model_name\", \"rank\", \"max_iter\", \"reg_param\", \"training_size\", \"trained_at\"])\n",
    "\n",
    "model_metadata.write.mode(\"overwrite\") \\\n",
    "    .jdbc(jdbc_url, \"models.metadata\", properties=properties)\n",
    "\n",
    "print(\"Model factors exported to PostgreSQL (schema: models)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symulacja serwowania: jak FastAPI użyłoby tych faktorów\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def get_recommendations_from_factors(user_id, top_n=10):\n",
    "    \"\"\"\n",
    "    Symulacja serwowania rekomendacji z PostgreSQL.\n",
    "    W prawdziwym API:\n",
    "    - user_factor ładowany z PostgreSQL (1 query)\n",
    "    - item_factors preloaded w pamięci (cache)\n",
    "    - numpy dot product → scores\n",
    "    \"\"\"\n",
    "    # Pobierz user factor\n",
    "    uf = user_factors.filter(col(\"user_id\") == user_id) \\\n",
    "        .select(\"features_json\").collect()\n",
    "    if not uf:\n",
    "        return None\n",
    "    \n",
    "    user_vec = np.array(json.loads(uf[0].features_json))\n",
    "    \n",
    "    # Pobierz item factors i policz score\n",
    "    all_items = item_factors.select(\"movie_id\", \"features_json\").collect()\n",
    "    \n",
    "    scores = []\n",
    "    for item in all_items:\n",
    "        item_vec = np.array(json.loads(item.features_json))\n",
    "        score = float(np.dot(user_vec, item_vec))\n",
    "        scores.append((item.movie_id, score))\n",
    "    \n",
    "    # Sort i top N\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores[:top_n]\n",
    "\n",
    "# Test\n",
    "start = time.time()\n",
    "recs = get_recommendations_from_factors(42)\n",
    "serving_time = time.time() - start\n",
    "\n",
    "print(f\"Recommendations for user 42 (computed in {serving_time:.3f}s):\")\n",
    "movie_names = {r.movie_id: r.title for r in movies.collect()}\n",
    "for movie_id, score in recs:\n",
    "    print(f\"  {movie_names.get(movie_id, 'Unknown')[:50]:<50} score={score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4000001",
   "metadata": {},
   "source": [
    "## 4. Batch Scoring Pipeline\n",
    "\n",
    "Generowanie rekomendacji dla WSZYSTKICH użytkowników w batchu.\n",
    "\n",
    "**Cron:** uruchamiaj co noc → aktualizuj tabelę rekomendacji → API czyta z niej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 rekomendacji dla wszystkich użytkowników\n",
    "start = time.time()\n",
    "all_recs = model.recommendForAllUsers(20)\n",
    "batch_time = time.time() - start\n",
    "print(f\"Batch scoring for {all_recs.count()} users: {batch_time:.1f}s\")\n",
    "\n",
    "# Rozpakuj rekomendacje do płaskiej tabeli\n",
    "recs_flat = all_recs.select(\n",
    "    col(\"user_id\"),\n",
    "    posexplode(\"recommendations\").alias(\"rank\", \"rec\")\n",
    ").select(\n",
    "    \"user_id\",\n",
    "    (col(\"rank\") + 1).alias(\"rank\"),\n",
    "    col(\"rec.movie_id\").alias(\"movie_id\"),\n",
    "    round(col(\"rec.rating\"), 4).alias(\"predicted_score\")\n",
    ")\n",
    "\n",
    "# Dodaj metadane\n",
    "recs_with_meta = recs_flat \\\n",
    "    .join(movies.select(\"movie_id\", \"title\", \"genres\"), \"movie_id\") \\\n",
    "    .withColumn(\"model_version\", lit(\"als_v1\")) \\\n",
    "    .withColumn(\"generated_at\", current_timestamp())\n",
    "\n",
    "print(f\"Total recommendations: {recs_with_meta.count()} rows\")\n",
    "recs_with_meta.filter(col(\"user_id\") == 42).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksport do PostgreSQL - gotowe do serwowania przez API\n",
    "recs_with_meta.select(\n",
    "    \"user_id\", \"rank\", \"movie_id\", \"title\", \"genres\",\n",
    "    \"predicted_score\", \"model_version\", \"generated_at\"\n",
    ").write.mode(\"overwrite\") \\\n",
    "    .jdbc(jdbc_url, \"recommendations.batch_recs\", properties=properties)\n",
    "\n",
    "print(\"Batch recommendations exported to PostgreSQL\")\n",
    "print(\"API query: SELECT * FROM recommendations.batch_recs WHERE user_id = ? ORDER BY rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000001",
   "metadata": {},
   "source": [
    "## 5. A/B Testing Framework\n",
    "\n",
    "Porównanie dwóch modeli na tym samym zbiorze danych.\n",
    "\n",
    "**Scenariusz:**\n",
    "- Model A: ALS z rank=10\n",
    "- Model B: ALS z rank=50\n",
    "- 50% użytkowników dostaje model A, 50% model B\n",
    "- Porównujemy metryki offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotuj train/test\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "train.cache()\n",
    "test.cache()\n",
    "\n",
    "# Model A: rank=10\n",
    "als_a = ALS(maxIter=10, regParam=0.1, rank=10,\n",
    "    userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\", seed=42)\n",
    "model_a = als_a.fit(train)\n",
    "\n",
    "# Model B: rank=50\n",
    "als_b = ALS(maxIter=10, regParam=0.1, rank=50,\n",
    "    userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\", seed=42)\n",
    "model_b = als_b.fit(train)\n",
    "\n",
    "print(\"Models trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losowe przypisanie użytkowników do grup A/B\n",
    "users = ratings.select(\"user_id\").distinct() \\\n",
    "    .withColumn(\"ab_group\",\n",
    "        when(crc32(col(\"user_id\").cast(\"string\")) % 2 == 0, \"A\")\n",
    "        .otherwise(\"B\")\n",
    "    )\n",
    "\n",
    "print(\"A/B group distribution:\")\n",
    "users.groupBy(\"ab_group\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offline metryki per model\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
    ")\n",
    "evaluator_mae = RegressionEvaluator(\n",
    "    metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Test set per grupa\n",
    "test_a = test.join(users.filter(col(\"ab_group\") == \"A\"), \"user_id\")\n",
    "test_b = test.join(users.filter(col(\"ab_group\") == \"B\"), \"user_id\")\n",
    "\n",
    "# Predykcje\n",
    "preds_a = model_a.transform(test_a)\n",
    "preds_b = model_b.transform(test_b)\n",
    "\n",
    "# Metryki\n",
    "results = {\n",
    "    \"Model A (rank=10)\": {\n",
    "        \"RMSE\": evaluator_rmse.evaluate(preds_a),\n",
    "        \"MAE\": evaluator_mae.evaluate(preds_a),\n",
    "        \"users\": test_a.select(\"user_id\").distinct().count(),\n",
    "        \"predictions\": preds_a.count()\n",
    "    },\n",
    "    \"Model B (rank=50)\": {\n",
    "        \"RMSE\": evaluator_rmse.evaluate(preds_b),\n",
    "        \"MAE\": evaluator_mae.evaluate(preds_b),\n",
    "        \"users\": test_b.select(\"user_id\").distinct().count(),\n",
    "        \"predictions\": preds_b.count()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== A/B Test Results ===\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\" if isinstance(value, float) else f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metrics per model\n",
    "K = 10\n",
    "\n",
    "def compute_precision_at_k(model, test_df, k=10):\n",
    "    \"\"\"Precision@K for a model.\"\"\"\n",
    "    # Ground truth: filmy ocenione >= 4.0\n",
    "    relevant = test_df.filter(col(\"rating\") >= 4.0) \\\n",
    "        .groupBy(\"user_id\") \\\n",
    "        .agg(collect_set(\"movie_id\").alias(\"relevant_movies\"))\n",
    "    \n",
    "    # Rekomendacje\n",
    "    recs = model.recommendForUserSubset(\n",
    "        test_df.select(\"user_id\").distinct(), k\n",
    "    ).select(\n",
    "        \"user_id\",\n",
    "        expr(\"transform(recommendations, x -> x.movie_id)\").alias(\"rec_movies\")\n",
    "    )\n",
    "    \n",
    "    # Precision@K\n",
    "    precision = recs.join(relevant, \"user_id\") \\\n",
    "        .withColumn(\"hits\", size(array_intersect(col(\"rec_movies\"), col(\"relevant_movies\")))) \\\n",
    "        .agg(round(avg(col(\"hits\") / k), 4).alias(\"precision_at_k\")) \\\n",
    "        .collect()[0][0]\n",
    "    \n",
    "    return precision\n",
    "\n",
    "prec_a = compute_precision_at_k(model_a, test_a)\n",
    "prec_b = compute_precision_at_k(model_b, test_b)\n",
    "\n",
    "print(f\"\\nPrecision@{K}:\")\n",
    "print(f\"  Model A (rank=10): {prec_a}\")\n",
    "print(f\"  Model B (rank=50): {prec_b}\")\n",
    "print(f\"  Winner: {'Model A' if prec_a > prec_b else 'Model B'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisz wyniki A/B testu\n",
    "ab_results = spark.createDataFrame([\n",
    "    (\"A\", \"als_rank10\", 10, results[\"Model A (rank=10)\"][\"RMSE\"],\n",
    "     results[\"Model A (rank=10)\"][\"MAE\"], float(prec_a or 0)),\n",
    "    (\"B\", \"als_rank50\", 50, results[\"Model B (rank=50)\"][\"RMSE\"],\n",
    "     results[\"Model B (rank=50)\"][\"MAE\"], float(prec_b or 0)),\n",
    "], [\"ab_group\", \"model_name\", \"rank\", \"rmse\", \"mae\", \"precision_at_10\"])\n",
    "\n",
    "ab_results.withColumn(\"test_date\", current_timestamp()) \\\n",
    "    .write.mode(\"overwrite\") \\\n",
    "    .jdbc(jdbc_url, \"experiments.ab_test_results\", properties=properties)\n",
    "\n",
    "ab_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6000001",
   "metadata": {},
   "source": [
    "## 6. Lambda Architecture - Batch + Speed Layer\n",
    "\n",
    "```\n",
    "                         ┌─────────────────┐\n",
    "  New Data ──────────────┤  Speed Layer     │──── Real-time view\n",
    "       │                 │  (Streaming)     │      (recent data)\n",
    "       │                 └─────────────────┘\n",
    "       │\n",
    "       └────────────────┐\n",
    "                        ▼\n",
    "                 ┌──────────────┐\n",
    "                 │  Batch Layer │──── Batch view\n",
    "                 │  (nightly)   │      (full history)\n",
    "                 └──────────────┘\n",
    "                                          \n",
    "                 ┌──────────────┐\n",
    "                 │ Serving Layer│──── Merge batch + speed\n",
    "                 │  (API/DB)    │      = complete view\n",
    "                 └──────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Layer: model wytrenowany na pełnych danych (co noc)\n",
    "# To już mamy - model ALS + batch recommendations\n",
    "\n",
    "# Speed Layer: aktualizacja popularności w real-time\n",
    "# Symulujmy strumień nowych ocen (ostatnie 24h)\n",
    "\n",
    "recent_ratings = ratings.filter(\n",
    "    col(\"rating_timestamp\") >= date_sub(current_date(), 30)  # ostatnie 30 dni w danych\n",
    ")\n",
    "\n",
    "# Real-time movie popularity (speed layer)\n",
    "speed_layer_stats = recent_ratings.groupBy(\"movie_id\").agg(\n",
    "    count(\"*\").alias(\"recent_ratings\"),\n",
    "    round(avg(\"rating\"), 2).alias(\"recent_avg_rating\"),\n",
    "    max(\"rating_timestamp\").alias(\"latest_rating\")\n",
    ")\n",
    "\n",
    "# Batch layer: historyczne statystyki\n",
    "batch_layer_stats = ratings.groupBy(\"movie_id\").agg(\n",
    "    count(\"*\").alias(\"total_ratings\"),\n",
    "    round(avg(\"rating\"), 2).alias(\"overall_avg_rating\")\n",
    ")\n",
    "\n",
    "# Serving Layer: merge batch + speed\n",
    "serving_view = batch_layer_stats \\\n",
    "    .join(speed_layer_stats, \"movie_id\", \"left\") \\\n",
    "    .join(movies.select(\"movie_id\", \"title\"), \"movie_id\") \\\n",
    "    .withColumn(\"trending_score\",\n",
    "        coalesce(col(\"recent_ratings\"), lit(0)) / col(\"total_ratings\")\n",
    "    ) \\\n",
    "    .fillna(0)\n",
    "\n",
    "print(\"Serving view - filmy z największym 'trending' (batch + speed):\")\n",
    "serving_view.orderBy(desc(\"trending_score\")) \\\n",
    "    .select(\"title\", \"total_ratings\", \"overall_avg_rating\",\n",
    "            \"recent_ratings\", \"recent_avg_rating\",\n",
    "            round(col(\"trending_score\"), 4).alias(\"trending\")) \\\n",
    "    .show(15, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7000001",
   "metadata": {},
   "source": [
    "## 7. End-to-End Pipeline: train → export → serve\n",
    "\n",
    "Pełny pipeline, jaki uruchamiałbyś co noc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nightly_pipeline():\n",
    "    \"\"\"Pełny nocny pipeline rekomendacji.\"\"\"\n",
    "    pipeline_start = time.time()\n",
    "    \n",
    "    # 1. Load data\n",
    "    print(\"[1/6] Loading data...\")\n",
    "    ratings = spark.read.jdbc(\n",
    "        jdbc_url, \"movielens.ratings\", properties=properties,\n",
    "        column=\"user_id\", lowerBound=1, upperBound=300000, numPartitions=10\n",
    "    ).cache()\n",
    "    movies = spark.read.jdbc(jdbc_url, \"movielens.movies\", properties=properties).cache()\n",
    "    n_ratings = ratings.count()\n",
    "    print(f\"   Loaded {n_ratings} ratings\")\n",
    "    \n",
    "    # 2. Train model\n",
    "    print(\"[2/6] Training ALS model...\")\n",
    "    als = ALS(\n",
    "        maxIter=10, regParam=0.1, rank=20,\n",
    "        userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\",\n",
    "        coldStartStrategy=\"drop\", seed=42\n",
    "    )\n",
    "    model = als.fit(ratings)\n",
    "    print(f\"   Model trained (rank={model.rank})\")\n",
    "    \n",
    "    # 3. Evaluate\n",
    "    print(\"[3/6] Evaluating...\")\n",
    "    (_, test) = ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "    preds = model.transform(test)\n",
    "    rmse = RegressionEvaluator(\n",
    "        metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
    "    ).evaluate(preds)\n",
    "    print(f\"   RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    # 4. Generate batch recommendations\n",
    "    print(\"[4/6] Generating batch recommendations...\")\n",
    "    all_recs = model.recommendForAllUsers(20)\n",
    "    recs_flat = all_recs.select(\n",
    "        \"user_id\",\n",
    "        posexplode(\"recommendations\").alias(\"rank\", \"rec\")\n",
    "    ).select(\n",
    "        \"user_id\", (col(\"rank\") + 1).alias(\"rank\"),\n",
    "        col(\"rec.movie_id\"), round(col(\"rec.rating\"), 4).alias(\"score\")\n",
    "    ).join(movies.select(\"movie_id\", \"title\"), \"movie_id\") \\\n",
    "     .withColumn(\"model_version\", lit(\"als_v1\")) \\\n",
    "     .withColumn(\"generated_at\", current_timestamp())\n",
    "    print(f\"   Generated {recs_flat.count()} recommendations\")\n",
    "    \n",
    "    # 5. Export to PostgreSQL\n",
    "    print(\"[5/6] Exporting to PostgreSQL...\")\n",
    "    recs_flat.write.mode(\"overwrite\") \\\n",
    "        .jdbc(jdbc_url, \"recommendations.batch_recs\", properties=properties)\n",
    "    \n",
    "    # Faktory modelu\n",
    "    model.userFactors.withColumnRenamed(\"id\", \"user_id\") \\\n",
    "        .withColumn(\"features_json\", to_json(col(\"features\").cast(ArrayType(DoubleType())))) \\\n",
    "        .select(\"user_id\", \"features_json\") \\\n",
    "        .write.mode(\"overwrite\") \\\n",
    "        .jdbc(jdbc_url, \"models.user_factors\", properties=properties)\n",
    "    \n",
    "    model.itemFactors.withColumnRenamed(\"id\", \"movie_id\") \\\n",
    "        .withColumn(\"features_json\", to_json(col(\"features\").cast(ArrayType(DoubleType())))) \\\n",
    "        .select(\"movie_id\", \"features_json\") \\\n",
    "        .write.mode(\"overwrite\") \\\n",
    "        .jdbc(jdbc_url, \"models.item_factors\", properties=properties)\n",
    "    print(\"   Export complete\")\n",
    "    \n",
    "    # 6. Log pipeline run\n",
    "    print(\"[6/6] Logging pipeline run...\")\n",
    "    total_time = time.time() - pipeline_start\n",
    "    \n",
    "    run_log = spark.createDataFrame([\n",
    "        (\"als_v1\", n_ratings, rmse, model.rank, total_time, \"success\")\n",
    "    ], [\"model_version\", \"training_size\", \"rmse\", \"rank\", \"duration_seconds\", \"status\"])\n",
    "    run_log.withColumn(\"run_at\", current_timestamp()) \\\n",
    "        .write.mode(\"append\") \\\n",
    "        .jdbc(jdbc_url, \"pipeline.run_log\", properties=properties)\n",
    "    \n",
    "    print(f\"\\nPipeline completed in {total_time:.1f}s\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    ratings.unpersist()\n",
    "    movies.unpersist()\n",
    "    \n",
    "    return model, rmse\n",
    "\n",
    "# Uruchom pipeline!\n",
    "model, rmse = run_nightly_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8000001",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "Rozbuduj nightly pipeline o:\n",
    "1. Feature store update (user_features + movie_features z sekcji 2)\n",
    "2. Data quality check na wejściu (min. 10M ratings, brak null w kluczach)\n",
    "3. A/B test: wytrenuj 2 modele (rank=10 i rank=30), porównaj RMSE\n",
    "4. Automatyczny wybór lepszego modelu\n",
    "5. Alert jeśli RMSE > threshold (np. 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9000001",
   "metadata": {},
   "source": [
    "## Zadanie końcowe\n",
    "\n",
    "Zbuduj **kompletny system rekomendacji** z:\n",
    "\n",
    "1. **Data Pipeline** (ETL)\n",
    "   - Bronze: surowe dane z PostgreSQL\n",
    "   - Silver: oczyszczone, wzbogacone\n",
    "   - Gold: feature store, model input\n",
    "\n",
    "2. **Model Pipeline**\n",
    "   - Train ALS z optymalnym rank (grid search)\n",
    "   - Ewaluacja: RMSE + Precision@10\n",
    "   - Export faktorów do PostgreSQL\n",
    "\n",
    "3. **Serving Pipeline**\n",
    "   - Batch recommendations (top 20 per user) → PostgreSQL\n",
    "   - Similar movies (top 10 per movie) → PostgreSQL\n",
    "   - Trending movies (last 30 days) → PostgreSQL\n",
    "\n",
    "4. **Monitoring**\n",
    "   - Pipeline run log z metrykami\n",
    "   - Porównanie z poprzednim modelem\n",
    "\n",
    "Wynikowe tabele PostgreSQL:\n",
    "- `recommendations.batch_recs` - rekomendacje per user\n",
    "- `recommendations.similar_movies` - podobne filmy\n",
    "- `recommendations.trending` - trendujące filmy\n",
    "- `features.user_features` - feature store\n",
    "- `features.movie_features` - feature store\n",
    "- `models.user_factors` / `item_factors` - wektory ALS\n",
    "- `pipeline.run_log` - log uruchomień"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
