{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1000001",
   "metadata": {},
   "source": [
    "# 05 - Spark SQL\n",
    "\n",
    "Nauka Spark SQL - pisanie zapytań SQL na danych Spark.\n",
    "\n",
    "**Tematy:**\n",
    "- Tworzenie widoków tymczasowych (createOrReplaceTempView)\n",
    "- Zapytania SQL: SELECT, WHERE, GROUP BY, HAVING\n",
    "- Podzapytania (subqueries) i CTE (WITH)\n",
    "- Funkcje okienkowe (window functions)\n",
    "- UDF w SQL\n",
    "- Łączenie DataFrame API z SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"05_Spark_SQL\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.1\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .config(\"spark.executor.memory\", \"7g\") \\\n",
    "    .config(\"spark.driver.host\", \"recommender-jupyter\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/recommender\"\n",
    "properties = {\n",
    "    \"user\": \"recommender\",\n",
    "    \"password\": \"recommender\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "ratings = spark.read.jdbc(\n",
    "    jdbc_url, \"movielens.ratings\", properties=properties,\n",
    "    column=\"user_id\", lowerBound=1, upperBound=300000, numPartitions=10\n",
    ")\n",
    "movies = spark.read.jdbc(jdbc_url, \"movielens.movies\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2000001",
   "metadata": {},
   "source": [
    "## 2. Tworzenie widoków tymczasowych\n",
    "\n",
    "Aby używać SQL w Spark, trzeba zarejestrować DataFrame jako widok tymczasowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# createOrReplaceTempView - widok w ramach sesji\n",
    "ratings.createOrReplaceTempView(\"ratings\")\n",
    "movies.createOrReplaceTempView(\"movies\")\n",
    "\n",
    "# Teraz możemy pisać SQL!\n",
    "spark.sql(\"SELECT * FROM ratings LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# createOrReplaceGlobalTempView - widok dostępny między sesjami\n",
    "# movies.createOrReplaceGlobalTempView(\"movies_global\")\n",
    "# spark.sql(\"SELECT * FROM global_temp.movies_global LIMIT 5\").show()\n",
    "\n",
    "# Sprawdź dostępne tabele\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000001",
   "metadata": {},
   "source": [
    "## 3. Podstawowe zapytania SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT z WHERE\n",
    "spark.sql(\"\"\"\n",
    "    SELECT user_id, movie_id, rating\n",
    "    FROM ratings\n",
    "    WHERE rating >= 4.5 AND user_id <= 100\n",
    "    ORDER BY rating DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP BY z HAVING\n",
    "spark.sql(\"\"\"\n",
    "    SELECT user_id, \n",
    "           COUNT(*) as rating_count, \n",
    "           ROUND(AVG(rating), 2) as avg_rating,\n",
    "           MIN(rating) as min_rating,\n",
    "           MAX(rating) as max_rating\n",
    "    FROM ratings\n",
    "    GROUP BY user_id\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY rating_count DESC\n",
    "    LIMIT 20\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN w SQL\n",
    "spark.sql(\"\"\"\n",
    "    SELECT m.title, \n",
    "           COUNT(*) as num_ratings, \n",
    "           ROUND(AVG(r.rating), 2) as avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movie_id = m.movie_id\n",
    "    GROUP BY m.title\n",
    "    HAVING COUNT(*) > 5000\n",
    "    ORDER BY avg_rating DESC\n",
    "    LIMIT 20\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000002",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "Napisz zapytanie SQL, które pokaże 10 najgorzej ocenianych filmów (z minimum 100 ocenami)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4000001",
   "metadata": {},
   "source": [
    "## 4. Podzapytania (Subqueries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podzapytanie w WHERE - użytkownicy, którzy ocenili więcej filmów niż średnia\n",
    "spark.sql(\"\"\"\n",
    "    SELECT user_id, COUNT(*) as cnt\n",
    "    FROM ratings\n",
    "    GROUP BY user_id\n",
    "    HAVING cnt > (\n",
    "        SELECT AVG(user_cnt)\n",
    "        FROM (\n",
    "            SELECT COUNT(*) as user_cnt\n",
    "            FROM ratings\n",
    "            GROUP BY user_id\n",
    "        )\n",
    "    )\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podzapytanie w FROM\n",
    "spark.sql(\"\"\"\n",
    "    SELECT rating_bucket, COUNT(*) as num_users\n",
    "    FROM (\n",
    "        SELECT user_id, \n",
    "               CASE \n",
    "                   WHEN AVG(rating) >= 4.0 THEN 'generous'\n",
    "                   WHEN AVG(rating) >= 3.0 THEN 'moderate'\n",
    "                   ELSE 'harsh'\n",
    "               END as rating_bucket\n",
    "        FROM ratings\n",
    "        GROUP BY user_id\n",
    "    )\n",
    "    GROUP BY rating_bucket\n",
    "    ORDER BY num_users DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXISTS / NOT EXISTS\n",
    "spark.sql(\"\"\"\n",
    "    SELECT m.movie_id, m.title\n",
    "    FROM movies m\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM ratings r WHERE r.movie_id = m.movie_id\n",
    "    )\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000001",
   "metadata": {},
   "source": [
    "## 5. CTE (Common Table Expressions) - WITH\n",
    "\n",
    "CTE pozwalają na tworzenie nazwanych podzapytań - czytelniejszy kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTE - profil użytkownika z kategorią aktywności\n",
    "spark.sql(\"\"\"\n",
    "    WITH user_stats AS (\n",
    "        SELECT user_id,\n",
    "               COUNT(*) as num_ratings,\n",
    "               ROUND(AVG(rating), 2) as avg_rating,\n",
    "               ROUND(STDDEV(rating), 2) as std_rating\n",
    "        FROM ratings\n",
    "        GROUP BY user_id\n",
    "    ),\n",
    "    user_categories AS (\n",
    "        SELECT *,\n",
    "               CASE\n",
    "                   WHEN num_ratings >= 1000 THEN 'power_user'\n",
    "                   WHEN num_ratings >= 100 THEN 'active'\n",
    "                   WHEN num_ratings >= 20 THEN 'casual'\n",
    "                   ELSE 'rare'\n",
    "               END as user_category\n",
    "        FROM user_stats\n",
    "    )\n",
    "    SELECT user_category,\n",
    "           COUNT(*) as num_users,\n",
    "           ROUND(AVG(avg_rating), 2) as mean_avg_rating,\n",
    "           ROUND(AVG(num_ratings), 0) as mean_num_ratings\n",
    "    FROM user_categories\n",
    "    GROUP BY user_category\n",
    "    ORDER BY mean_num_ratings DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTE z wieloma krokami - top filmy per gatunek\n",
    "spark.sql(\"\"\"\n",
    "    WITH movie_ratings AS (\n",
    "        SELECT m.movie_id, m.title, m.genres,\n",
    "               COUNT(*) as num_ratings,\n",
    "               ROUND(AVG(r.rating), 2) as avg_rating\n",
    "        FROM movies m\n",
    "        JOIN ratings r ON m.movie_id = r.movie_id\n",
    "        GROUP BY m.movie_id, m.title, m.genres\n",
    "        HAVING COUNT(*) >= 500\n",
    "    ),\n",
    "    comedy_top AS (\n",
    "        SELECT title, avg_rating, num_ratings, 'Comedy' as genre\n",
    "        FROM movie_ratings\n",
    "        WHERE genres LIKE '%Comedy%'\n",
    "        ORDER BY avg_rating DESC\n",
    "        LIMIT 5\n",
    "    ),\n",
    "    drama_top AS (\n",
    "        SELECT title, avg_rating, num_ratings, 'Drama' as genre\n",
    "        FROM movie_ratings\n",
    "        WHERE genres LIKE '%Drama%'\n",
    "        ORDER BY avg_rating DESC\n",
    "        LIMIT 5\n",
    "    )\n",
    "    SELECT * FROM comedy_top\n",
    "    UNION ALL\n",
    "    SELECT * FROM drama_top\n",
    "    ORDER BY genre, avg_rating DESC\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000002",
   "metadata": {},
   "source": [
    "### Zadanie 2\n",
    "Napisz zapytanie z CTE, które:\n",
    "1. Znajdzie użytkowników, którzy ocenili >500 filmów\n",
    "2. Dla tych użytkowników policzy ile filmów ocenili na 5.0\n",
    "3. Pokaże top 10 użytkowników z największym % ocen 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6000001",
   "metadata": {},
   "source": [
    "## 6. Funkcje okienkowe (Window Functions)\n",
    "\n",
    "Window functions pozwalają na obliczenia w kontekście \"okna\" wierszy, bez redukowania liczby wierszy (w przeciwieństwie do GROUP BY).\n",
    "\n",
    "- `ROW_NUMBER()` - numer wiersza w oknie\n",
    "- `RANK()` / `DENSE_RANK()` - ranking\n",
    "- `LAG()` / `LEAD()` - poprzedni/następny wiersz\n",
    "- `SUM() OVER` / `AVG() OVER` - kumulatywne/ruchome agregacje\n",
    "- `NTILE(n)` - podział na n grup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROW_NUMBER - numeracja wierszy w oknie\n",
    "# Np. top 3 najwyżej ocenionych filmów per użytkownik\n",
    "spark.sql(\"\"\"\n",
    "    SELECT user_id, movie_id, rating, rn\n",
    "    FROM (\n",
    "        SELECT user_id, movie_id, rating,\n",
    "               ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY rating DESC) as rn\n",
    "        FROM ratings\n",
    "    )\n",
    "    WHERE rn <= 3 AND user_id <= 5\n",
    "    ORDER BY user_id, rn\n",
    "\"\"\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANK vs DENSE_RANK\n",
    "# RANK: 1, 2, 2, 4 (pomija pozycje)\n",
    "# DENSE_RANK: 1, 2, 2, 3 (nie pomija)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT user_id, movie_id, rating,\n",
    "           RANK() OVER (PARTITION BY user_id ORDER BY rating DESC) as rank,\n",
    "           DENSE_RANK() OVER (PARTITION BY user_id ORDER BY rating DESC) as dense_rank\n",
    "    FROM ratings\n",
    "    WHERE user_id = 1\n",
    "    LIMIT 15\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAG / LEAD - poprzedni/następny wiersz\n",
    "# Pokaż jak zmieniała się ocena użytkownika w czasie\n",
    "spark.sql(\"\"\"\n",
    "    SELECT user_id, movie_id, rating, rating_timestamp,\n",
    "           LAG(rating) OVER (PARTITION BY user_id ORDER BY rating_timestamp) as prev_rating,\n",
    "           rating - LAG(rating) OVER (PARTITION BY user_id ORDER BY rating_timestamp) as rating_diff\n",
    "    FROM ratings\n",
    "    WHERE user_id = 42\n",
    "    ORDER BY rating_timestamp\n",
    "    LIMIT 20\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kumulatywna suma i średnia krocząca\n",
    "spark.sql(\"\"\"\n",
    "    SELECT user_id, movie_id, rating, rating_timestamp,\n",
    "           COUNT(*) OVER (PARTITION BY user_id ORDER BY rating_timestamp) as cumulative_count,\n",
    "           ROUND(AVG(rating) OVER (\n",
    "               PARTITION BY user_id \n",
    "               ORDER BY rating_timestamp \n",
    "               ROWS BETWEEN 4 PRECEDING AND CURRENT ROW\n",
    "           ), 2) as moving_avg_5\n",
    "    FROM ratings\n",
    "    WHERE user_id = 42\n",
    "    ORDER BY rating_timestamp\n",
    "    LIMIT 20\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NTILE - podział na kwartyle\n",
    "spark.sql(\"\"\"\n",
    "    WITH user_avg AS (\n",
    "        SELECT user_id, AVG(rating) as avg_rating, COUNT(*) as cnt\n",
    "        FROM ratings\n",
    "        GROUP BY user_id\n",
    "        HAVING COUNT(*) >= 50\n",
    "    )\n",
    "    SELECT \n",
    "        quartile,\n",
    "        COUNT(*) as num_users,\n",
    "        ROUND(MIN(avg_rating), 2) as min_avg,\n",
    "        ROUND(MAX(avg_rating), 2) as max_avg\n",
    "    FROM (\n",
    "        SELECT *, NTILE(4) OVER (ORDER BY avg_rating) as quartile\n",
    "        FROM user_avg\n",
    "    )\n",
    "    GROUP BY quartile\n",
    "    ORDER BY quartile\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6000002",
   "metadata": {},
   "source": [
    "### Zadanie 3\n",
    "Użyj window functions, żeby znaleźć dla każdego użytkownika (id <= 50) jego:\n",
    "- pierwszą ocenę (chronologicznie)\n",
    "- ostatnią ocenę\n",
    "- różnicę między nimi\n",
    "\n",
    "Pokaż użytkowników, którzy z czasem stali się bardziej surowi (ostatnia ocena niższa od pierwszej)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7000001",
   "metadata": {},
   "source": [
    "## 7. Window Functions z DataFrame API\n",
    "\n",
    "Te same operacje okienkowe można wykonać w DataFrame API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, rank, dense_rank, lag, lead, col, avg, count, desc\n",
    "\n",
    "# Zdefiniuj okno\n",
    "user_window = Window.partitionBy(\"user_id\").orderBy(desc(\"rating\"))\n",
    "\n",
    "# Top 3 filmy per użytkownik\n",
    "top_movies = ratings \\\n",
    "    .withColumn(\"rn\", row_number().over(user_window)) \\\n",
    "    .filter(col(\"rn\") <= 3) \\\n",
    "    .filter(col(\"user_id\") <= 5)\n",
    "\n",
    "top_movies.orderBy(\"user_id\", \"rn\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Średnia krocząca\n",
    "time_window = Window.partitionBy(\"user_id\") \\\n",
    "    .orderBy(\"rating_timestamp\") \\\n",
    "    .rowsBetween(-4, 0)\n",
    "\n",
    "ratings.filter(col(\"user_id\") == 42) \\\n",
    "    .withColumn(\"moving_avg\", avg(\"rating\").over(time_window)) \\\n",
    "    .select(\"user_id\", \"movie_id\", \"rating\", \"rating_timestamp\", \"moving_avg\") \\\n",
    "    .orderBy(\"rating_timestamp\") \\\n",
    "    .show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8000001",
   "metadata": {},
   "source": [
    "## 8. UDF (User-Defined Functions) w SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, ArrayType\n",
    "\n",
    "# Zdefiniuj Python UDF\n",
    "def extract_year(title):\n",
    "    \"\"\"Wyciąga rok z tytułu filmu, np. 'Toy Story (1995)' -> '1995'\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'\\((\\d{4})\\)', title or '')\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def genres_to_list(genres):\n",
    "    \"\"\"Zamienia 'Comedy|Drama' na ['Comedy', 'Drama']\"\"\"\n",
    "    return (genres or '').split('|')\n",
    "\n",
    "# Zarejestruj UDFy w Spark SQL\n",
    "spark.udf.register(\"extract_year\", extract_year, StringType())\n",
    "spark.udf.register(\"genres_to_list\", genres_to_list, ArrayType(StringType()))\n",
    "\n",
    "# Użyj w SQL\n",
    "spark.sql(\"\"\"\n",
    "    SELECT title, \n",
    "           extract_year(title) as year,\n",
    "           genres,\n",
    "           genres_to_list(genres) as genre_list\n",
    "    FROM movies\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF w analizie - rozkład filmów per dekada\n",
    "spark.sql(\"\"\"\n",
    "    SELECT CONCAT(FLOOR(CAST(extract_year(title) AS INT) / 10) * 10, 's') as decade,\n",
    "           COUNT(*) as num_movies\n",
    "    FROM movies\n",
    "    WHERE extract_year(title) IS NOT NULL\n",
    "    GROUP BY decade\n",
    "    ORDER BY decade\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9000001",
   "metadata": {},
   "source": [
    "## 9. Mieszanie SQL z DataFrame API\n",
    "\n",
    "Wynik `spark.sql()` to zwykły DataFrame - można go dalej przetwarzać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL -> DataFrame API\n",
    "popular_movies = spark.sql(\"\"\"\n",
    "    SELECT movie_id, COUNT(*) as num_ratings, AVG(rating) as avg_rating\n",
    "    FROM ratings\n",
    "    GROUP BY movie_id\n",
    "    HAVING COUNT(*) > 1000\n",
    "\"\"\")\n",
    "\n",
    "# Kontynuuj z DataFrame API\n",
    "result = popular_movies \\\n",
    "    .join(movies, \"movie_id\") \\\n",
    "    .filter(col(\"avg_rating\") >= 4.0) \\\n",
    "    .orderBy(desc(\"num_ratings\")) \\\n",
    "    .select(\"title\", \"num_ratings\", \"avg_rating\")\n",
    "\n",
    "result.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame API -> SQL\n",
    "# Wynik DataFrame API może być widokiem do SQL\n",
    "result.createOrReplaceTempView(\"popular_good_movies\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT title, num_ratings, ROUND(avg_rating, 2) as avg_rating\n",
    "    FROM popular_good_movies\n",
    "    WHERE num_ratings > 10000\n",
    "    ORDER BY avg_rating DESC\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10000001",
   "metadata": {},
   "source": [
    "## Zadanie końcowe\n",
    "\n",
    "Napisz zapytanie SQL (możesz użyć CTE i window functions), które znajdzie:\n",
    "\n",
    "Dla każdego gatunku filmowego (rozbij genres na poszczególne gatunki za pomocą UDF):\n",
    "1. Liczbę filmów\n",
    "2. Średnią ocenę\n",
    "3. Film z najwyższą średnią oceną (min. 100 ocen) - użyj ROW_NUMBER\n",
    "4. Ranking gatunków po popularności (liczba ocen)\n",
    "\n",
    "Wynik posortuj po liczbie filmów malejąco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twoje rozwiązanie:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
